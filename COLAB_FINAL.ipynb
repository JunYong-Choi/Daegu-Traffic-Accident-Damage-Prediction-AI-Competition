{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qji_FLehXZiI"
   },
   "source": [
    "# Environment\n",
    "- COLAB PRO PLUS , GPU: A100 ,  고용량 RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NTtZ44lLXZiK"
   },
   "source": [
    "## Library version check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7UEOcJ1jXbw0"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B0wHRDs9XybX"
   },
   "outputs": [],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3dyAhgGGXZiL",
    "outputId": "e32d3581-b891-4d4d-dce8-3acd9c657309"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Python & library version --------------------------\n",
      "Python version: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
      "pandas version: 1.5.3\n",
      "numpy version: 1.23.5\n",
      "matplotlib version: 3.7.1\n",
      "tqdm version: 4.66.1\n",
      "xgboost version: 2.0.2\n",
      "lightgbm version: 4.1.0\n",
      "catboost version: 1.2.2\n",
      "seaborn version: 0.12.2\n",
      "scikit-learn version: 1.2.2\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tqdm as tq\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cat\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "print(\"-------------------------- Python & library version --------------------------\")\n",
    "print(\"Python version: {}\".format(sys.version))\n",
    "print(\"pandas version: {}\".format(pd.__version__))\n",
    "print(\"numpy version: {}\".format(np.__version__))\n",
    "print(\"matplotlib version: {}\".format(matplotlib.__version__))\n",
    "print(\"tqdm version: {}\".format(tq.__version__))\n",
    "print(\"xgboost version: {}\".format(xgb.__version__))\n",
    "print(\"lightgbm version: {}\".format(lgb.__version__))\n",
    "print(\"catboost version: {}\".format(cat.__version__))\n",
    "print(\"seaborn version: {}\".format(sns.__version__))\n",
    "print(\"scikit-learn version: {}\".format(skl.__version__))\n",
    "print(\"------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBSqx61hXZiM"
   },
   "source": [
    "## 0. Load the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "amG26zh-XZiM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import MultiPolygon\n",
    "from pyproj import Proj, transform\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 30)\n",
    "\n",
    "#Seed 고정\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "#Eval metric\n",
    "def rmsle(y_true, y_pred):\n",
    "    return mean_squared_log_error(y_true, y_pred) ** 0.5\n",
    "\n",
    "#시각화 설정\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['font.size'] = 15\n",
    "\n",
    "# 운영체제별 한글 폰트 설정\n",
    "if os.name == 'posix': # Mac 환경 폰트 설정\n",
    "    plt.rc('font', family='AppleGothic')\n",
    "elif os.name == 'nt': # Windows 환경 폰트 설정\n",
    "    plt.rc('font', family='Malgun Gothic')\n",
    "\n",
    "plt.rc('axes', unicode_minus=False) # 마이너스 폰트 설정\n",
    "\n",
    "\n",
    "# 글씨 선명하게 출력하는 설정\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5kkyU_rXZiN"
   },
   "source": [
    "## 1. Load Data (외부데이터(공공데이터 포털), CCTV, 보안등, 주차장, 어린이보호구역)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tA6QkTUUXZiQ"
   },
   "outputs": [],
   "source": [
    "#대구 교통사고 추가데이터\n",
    "additional_1 = pd.read_csv('/content/drive/MyDrive/대구_교통사고_피해_예측_AI경진대회/open/data/외부데이터1_csv.csv', encoding='utf-8')[['사고번호','사고일시','요일','기상상태','시군구','도로형태','노면상태','사고유형','사망자수','중상자수','경상자수','부상신고자수']]\n",
    "additional_2 = pd.read_csv('/content/drive/MyDrive/대구_교통사고_피해_예측_AI경진대회/open/data/외부데이터2_csv.csv', encoding='utf-8')[['사고번호','사고일시','요일','기상상태','시군구','도로형태','노면상태','사고유형','사망자수','중상자수','경상자수','부상신고자수']]\n",
    "additional_3 = pd.read_csv('/content/drive/MyDrive/대구_교통사고_피해_예측_AI경진대회/open/data/외부데이터3_csv.csv', encoding='utf-8')[['사고번호','사고일시','요일','기상상태','시군구','도로형태','노면상태','사고유형','사망자수','중상자수','경상자수','부상신고자수']]\n",
    "additional_4 = pd.read_csv('/content/drive/MyDrive/대구_교통사고_피해_예측_AI경진대회/open/data/외부데이터4_csv.csv', encoding='utf-8')[['사고번호','사고일시','요일','기상상태','시군구','도로형태','노면상태','사고유형','사망자수','중상자수','경상자수','부상신고자수']]\n",
    "\n",
    "additional = pd.concat([additional_1,additional_2,additional_3,additional_4], axis = 0).reset_index(drop=True)\n",
    "\n",
    "additional.rename(columns={'사고번호': 'ID'}, inplace=True)\n",
    "additional['사고일시'] = pd.to_datetime(additional['사고일시'], format='%Y년 %m월 %d일 %H시')\n",
    "additional['사고유형'] = additional['사고유형'].str.split(' - ').str[0]\n",
    "\n",
    "additional.rename(columns={'부상신고자수':'부상자수'}, inplace = True)\n",
    "\n",
    "additional['ECLO'] = additional['사망자수'] * 10 + additional['중상자수'] * 5 + additional['경상자수'] * 3 + additional['부상자수'] * 1\n",
    "\n",
    "additional.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "FcuxmYL4XZiQ"
   },
   "outputs": [],
   "source": [
    "#시간 정보 추출\n",
    "\n",
    "for df in [additional]:\n",
    "    df['연'] = df['사고일시'].dt.year\n",
    "    df['월'] = df['사고일시'].dt.month\n",
    "    df['일'] = df['사고일시'].dt.day\n",
    "    df['monthday'] = df.apply(lambda row: str(row['월']) + '-' + str(row['일']), axis=1)\n",
    "    df['시간'] = df['사고일시'].dt.hour\n",
    "    df['weekday'] = df['사고일시'].dt.weekday\n",
    "    df['weekofyear'] = (df['사고일시'].dt.isocalendar().week).astype(int)\n",
    "\n",
    "    df['새벽'] = df['시간'].isin([0,1,2,3,4,5,6]).astype(int)\n",
    "    df['밤'] = df['시간'].isin([21,22,23]).astype(int)\n",
    "    df['주말'] = df['weekday'].isin([5,6]).astype(int)\n",
    "    df['주중'] = df['weekday'].isin([0,1,2,3,4]).astype(int)\n",
    "    df['국가공휴일_상준'] = df['monthday'].isin(['1-1','3-1','5-5','6-6','8-15','10-3','10-9','12-25','12-31']).astype(int)\n",
    "\n",
    "additional = additional.drop(columns=['사고일시','monthday'])\n",
    "\n",
    "#지역 정보 추출\n",
    "location_pattern = r'(\\S+) (\\S+) (\\S+)'\n",
    "\n",
    "additional[['도시', '구', '동']] = additional['시군구'].str.extract(location_pattern)\n",
    "additional = additional.drop(columns=['시군구'])\n",
    "\n",
    "#도로 정보 추출\n",
    "road_pattern = r'(.+) - (.+)'\n",
    "\n",
    "additional[['도로형태1', '도로형태2']] = additional['도로형태'].str.extract(road_pattern)\n",
    "additional = additional.drop(columns=['도로형태'])\n",
    "\n",
    "additional['사고유형_도로형태2'] = additional['사고유형'] + '_' + additional['도로형태2']\n",
    "\n",
    "additional.dropna(subset = ['도시','구','동'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T12:27:59.425208Z",
     "iopub.status.busy": "2023-11-19T12:27:59.424927Z",
     "iopub.status.idle": "2023-11-19T12:27:59.434212Z",
     "shell.execute_reply": "2023-11-19T12:27:59.433388Z",
     "shell.execute_reply.started": "2023-11-19T12:27:59.425184Z"
    },
    "id": "OBDcCYAnXZiR"
   },
   "outputs": [],
   "source": [
    "#보안등 데이터\n",
    "light_df = pd.read_csv('/content/drive/MyDrive/대구_교통사고_피해_예측_AI경진대회/open/data/대구 보안등 정보.csv', encoding='cp949')[['설치개수', '위도', '경도', '설치연도', '설치형태', '소재지지번주소']]\n",
    "\n",
    "light_df['위도'] = light_df['위도'].fillna(light_df['위도'].mean())\n",
    "light_df['경도'] = light_df['경도'].fillna(light_df['경도'].mean())\n",
    "light_df['설치연도'] = light_df['설치연도'].fillna(light_df['설치연도'].mode()[0])\n",
    "light_df['설치형태'] = light_df['설치형태'].fillna(light_df['설치형태'].mode()[0])\n",
    "\n",
    "location_pattern = r'(\\S+) (\\S+) (\\S+) (\\S+)'\n",
    "\n",
    "light_df[['도시', '구', '동', '번지']] = light_df['소재지지번주소'].str.extract(location_pattern)\n",
    "\n",
    "location_pattern = r'(\\S+) (\\S+) (\\S+)'\n",
    "light_df.loc[light_df['도시'].isna(), '도시'] = light_df.loc[light_df['도시'].isna(), '소재지지번주소'].str.extract(location_pattern).iloc[:,0]\n",
    "light_df.loc[light_df['구'].isna(), '구'] = light_df.loc[light_df['구'].isna(), '소재지지번주소'].str.extract(location_pattern).iloc[:,1]\n",
    "light_df.loc[light_df['동'].isna(), '동'] = light_df.loc[light_df['동'].isna(), '소재지지번주소'].str.extract(location_pattern).iloc[:,2]\n",
    "\n",
    "location_pattern = r'(\\S+) (\\S+)'\n",
    "light_df.loc[light_df['도시'].isna(), '도시'] = light_df.loc[light_df['도시'].isna(), '소재지지번주소'].str.extract(location_pattern).iloc[:,0]\n",
    "light_df.loc[light_df['구'].isna(), '구'] = light_df.loc[light_df['구'].isna(), '소재지지번주소'].str.extract(location_pattern).iloc[:,1]\n",
    "light_df['동'] = light_df['동'].fillna(\"신암동\")\n",
    "\n",
    "light_df.loc[light_df['동'].str.contains(\"-\"), '동'] = light_df.loc[light_df['동'].str.contains(\"-\"), '동'].apply(lambda x : re.sub(r'\\d+-\\d+', '', x))\n",
    "light_df.loc[light_df['동'].str.contains(\"동\"), '동'] = light_df.loc[light_df['동'].str.contains(\"동\"), '동'].apply(lambda x : re.sub(r'\\d\\d+', '', x))\n",
    "light_df.loc[light_df['동'] == '', '동'] = \"신암동\"\n",
    "\n",
    "light_df = light_df.drop(columns=['소재지지번주소', '번지'])\n",
    "\n",
    "light_df['설치형태'] = light_df['설치형태'].fillna(light_df['설치형태'].mode()[0])\n",
    "\n",
    "#보안등 동이름 그룹핑\n",
    "light_df.loc[light_df['동']==\"내당1동\", \"동\"] = \"내당동\"\n",
    "light_df.loc[light_df['동']==\"내당2·3동\", \"동\"] = \"내당동\"\n",
    "light_df.loc[light_df['동']==\"내당4동\", \"동\"] = \"내당동\"\n",
    "light_df.loc[light_df['동']==\"대현1동\", \"동\"] = \"대현동\"\n",
    "light_df.loc[light_df['동']==\"대현2동\", \"동\"] = \"대현동\"\n",
    "light_df.loc[light_df['동']==\"도평로131\", \"동\"] = \"도동\"\n",
    "light_df.loc[light_df['동']==\"만촌1동\", \"동\"] = \"만촌동\"\n",
    "light_df.loc[light_df['동']==\"만촌2동\", \"동\"] = \"만촌동\"\n",
    "light_df.loc[light_df['동']==\"만촌3동\", \"동\"] = \"만촌동\"\n",
    "light_df.loc[light_df['동']==\"범물1동\", \"동\"] = \"범물동\"\n",
    "light_df.loc[light_df['동']==\"범물2동\", \"동\"] = \"범물동\"\n",
    "light_df.loc[light_df['동']==\"범어1동\", \"동\"] = \"범어동\"\n",
    "light_df.loc[light_df['동']==\"범어2동\", \"동\"] = \"범어동\"\n",
    "light_df.loc[light_df['동']==\"범어3동\", \"동\"] = \"범어동\"\n",
    "light_df.loc[light_df['동']==\"범어4동\", \"동\"] = \"범어동\"\n",
    "light_df.loc[light_df['동']==\"범물1동\", \"동\"] = \"범물동\"\n",
    "light_df.loc[light_df['동']==\"범물2동\", \"동\"] = \"범물동\"\n",
    "light_df.loc[light_df['동']==\"복현1동\", \"동\"] = \"복현동\"\n",
    "light_df.loc[light_df['동']==\"부동길\", \"동\"] = \"부동\"\n",
    "light_df.loc[light_df['동']==\"비산1동\", \"동\"] = \"비산동\"\n",
    "light_df.loc[light_df['동']==\"비산2·3동\", \"동\"] = \"비산동\"\n",
    "light_df.loc[light_df['동']==\"비산4동\", \"동\"] = \"비산동\"\n",
    "light_df.loc[light_df['동']==\"비산7동\", \"동\"] = \"비산동\"\n",
    "light_df.loc[light_df['동']==\"산격1동\", \"동\"] = \"산격동\"\n",
    "light_df.loc[light_df['동']==\"산격2동\", \"동\"] = \"산격동\"\n",
    "light_df.loc[light_df['동']==\"산격3동\", \"동\"] = \"산격동\"\n",
    "light_df.loc[light_df['동']==\"산격4동\", \"동\"] = \"산격동\"\n",
    "light_df.loc[light_df['동']==\"송촌리\", \"동\"] = \"옥포읍\"\n",
    "light_df.loc[light_df['동']==\"수성1가동\", \"동\"] = \"수성동1가\"\n",
    "light_df.loc[light_df['동']==\"수성2.3가동\", \"동\"] = \"수성동2가\"\n",
    "light_df.loc[light_df['동']==\"수성4가동\", \"동\"] = \"수성동4가\"\n",
    "light_df.loc[light_df['동']==\"신암5동\", \"동\"] = \"신암동\"\n",
    "light_df.loc[light_df['동']==\"옥포면\", \"동\"] = \"옥포읍\"\n",
    "light_df.loc[light_df['동']==\"원교리\", \"동\"] = \"현풍읍\"\n",
    "light_df.loc[light_df['동']==\"유가면\", \"동\"] = \"유가읍\"\n",
    "light_df.loc[light_df['동']==\"유곡리\", \"동\"] = \"유가읍\"\n",
    "light_df.loc[light_df['동']==\"입석로\", \"동\"] = \"입석동\"\n",
    "light_df.loc[light_df['동']==\"지산1동\", \"동\"] = \"지산동\"\n",
    "light_df.loc[light_df['동']==\"지산2동\", \"동\"] = \"지산동\"\n",
    "light_df.loc[light_df['동']==\"침산1동\", \"동\"] = \"침산동\"\n",
    "light_df.loc[light_df['동']==\"침산3동\", \"동\"] = \"침산동\"\n",
    "light_df.loc[light_df['동']==\"태전1동\", \"동\"] = \"태전동\"\n",
    "light_df.loc[light_df['동']==\"태전2동\", \"동\"] = \"태전동\"\n",
    "light_df.loc[light_df['동']==\"팔공로\", \"동\"] = \"봉무동\"\n",
    "light_df.loc[light_df['동']==\"평리1동\", \"동\"] = \"평리동\"\n",
    "light_df.loc[light_df['동']==\"평리2동\", \"동\"] = \"평리동\"\n",
    "light_df.loc[light_df['동']==\"평리3동\", \"동\"] = \"평리동\"\n",
    "light_df.loc[light_df['동']==\"평리4동\", \"동\"] = \"평리동\"\n",
    "light_df.loc[light_df['동']==\"평리5동\", \"동\"] = \"평리동\"\n",
    "light_df.loc[light_df['동']==\"평리6동\", \"동\"] = \"평리동\"\n",
    "light_df.loc[light_df['동']==\"한정리\", \"동\"] = \"유가읍\"\n",
    "light_df.loc[light_df['동']==\"현풍면\", \"동\"] = \"현풍읍\"\n",
    "light_df.loc[light_df['동']==\"황금1동\", \"동\"] = \"황금동\"\n",
    "light_df.loc[light_df['동']==\"황금2동\", \"동\"] = \"황금동\"\n",
    "\n",
    "light_df_1 = light_df[['도시', '구', '동', '설치개수']].groupby(['도시', '구', '동']).sum().reset_index()\n",
    "light_df_1.reset_index(inplace=True, drop=True)\n",
    "light_df_1.rename(columns = {'설치개수':'보안등_설치총개수'}, inplace = True)\n",
    "\n",
    "light_df_2 = light_df[['도시', '구', '동', '설치개수']].groupby(['도시', '구', '동']).mean().reset_index()\n",
    "light_df_2.reset_index(inplace=True, drop=True)\n",
    "light_df_2.rename(columns = {'설치개수':'보안등_평균설치개수'}, inplace = True)\n",
    "\n",
    "light_df_3 = light_df[['도시', '구', '동', '위도']].groupby(['도시', '구', '동']).mean().reset_index()\n",
    "light_df_3.reset_index(inplace=True, drop=True)\n",
    "light_df_3.rename(columns = {'위도':'보안등_평균위도'}, inplace = True)\n",
    "\n",
    "light_df_4 = light_df[['도시', '구', '동', '위도']].groupby(['도시', '구', '동']).min().reset_index()\n",
    "light_df_4.reset_index(inplace=True, drop=True)\n",
    "light_df_4.rename(columns = {'위도':'보안등_최저위도'}, inplace = True)\n",
    "\n",
    "light_df_5 = light_df[['도시', '구', '동', '위도']].groupby(['도시', '구', '동']).max().reset_index()\n",
    "light_df_5.reset_index(inplace=True, drop=True)\n",
    "light_df_5.rename(columns = {'위도':'보안등_최고위도'}, inplace = True)\n",
    "\n",
    "light_df_6 = light_df[['도시', '구', '동', '경도']].groupby(['도시', '구', '동']).mean().reset_index()\n",
    "light_df_6.reset_index(inplace=True, drop=True)\n",
    "light_df_6.rename(columns = {'경도':'보안등_평균경도'}, inplace = True)\n",
    "\n",
    "light_df_7 = light_df[['도시', '구', '동', '경도']].groupby(['도시', '구', '동']).min().reset_index()\n",
    "light_df_7.reset_index(inplace=True, drop=True)\n",
    "light_df_7.rename(columns = {'경도':'보안등_최저경도'}, inplace = True)\n",
    "\n",
    "light_df_8 = light_df[['도시', '구', '동', '경도']].groupby(['도시', '구', '동']).max().reset_index()\n",
    "light_df_8.reset_index(inplace=True, drop=True)\n",
    "light_df_8.rename(columns = {'경도':'보안등_최고경도'}, inplace = True)\n",
    "\n",
    "light_df_9 = light_df[['도시', '구', '동', '설치연도']].groupby(['도시', '구', '동']).mean().reset_index()\n",
    "light_df_9.reset_index(inplace=True, drop=True)\n",
    "light_df_9.rename(columns = {'설치연도':'보안등_평균설치연도'}, inplace = True)\n",
    "\n",
    "light_df_10 = light_df[['도시', '구', '동', '설치연도']].groupby(['도시', '구', '동']).min().reset_index()\n",
    "light_df_10.reset_index(inplace=True, drop=True)\n",
    "light_df_10.rename(columns = {'설치연도':'보안등_최소설치연도'}, inplace = True)\n",
    "\n",
    "light_df_11 = light_df[['도시', '구', '동', '설치연도']].groupby(['도시', '구', '동']).max().reset_index()\n",
    "light_df_11.reset_index(inplace=True, drop=True)\n",
    "light_df_11.rename(columns = {'설치연도':'보안등_최대설치연도'}, inplace = True)\n",
    "\n",
    "light_df_12 = light_df[['도시', '구', '동', '설치형태']].groupby(['도시', '구', '동']).nunique().reset_index()\n",
    "light_df_12.reset_index(inplace=True, drop=True)\n",
    "light_df_12.rename(columns = {'설치형태':'보안등_설치형태종류수'}, inplace = True)\n",
    "\n",
    "light_df = pd.merge(light_df_1, light_df_2, how='left', on=['도시', '구', '동'])\n",
    "light_df = pd.merge(light_df, light_df_3, how='left', on=['도시', '구', '동'])\n",
    "light_df = pd.merge(light_df, light_df_4, how='left', on=['도시', '구', '동'])\n",
    "light_df = pd.merge(light_df, light_df_5, how='left', on=['도시', '구', '동'])\n",
    "light_df = pd.merge(light_df, light_df_6, how='left', on=['도시', '구', '동'])\n",
    "light_df = pd.merge(light_df, light_df_7, how='left', on=['도시', '구', '동'])\n",
    "light_df = pd.merge(light_df, light_df_8, how='left', on=['도시', '구', '동'])\n",
    "light_df = pd.merge(light_df, light_df_9, how='left', on=['도시', '구', '동'])\n",
    "light_df = pd.merge(light_df, light_df_10, how='left', on=['도시', '구', '동'])\n",
    "light_df = pd.merge(light_df, light_df_11, how='left', on=['도시', '구', '동'])\n",
    "light_df = pd.merge(light_df, light_df_12, how='left', on=['도시', '구', '동'])\n",
    "\n",
    "light_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BA8iAphTXZiR"
   },
   "outputs": [],
   "source": [
    "#어린이 보호구역 데이터\n",
    "child_area_df = pd.read_csv('/content/drive/MyDrive/대구_교통사고_피해_예측_AI경진대회/open/data/대구 어린이 보호 구역 정보.csv', encoding='cp949').drop_duplicates()[['CCTV설치대수', '위도', '경도','보호구역도로폭','소재지지번주소']]\n",
    "child_area_df.dropna(subset = ['소재지지번주소'], inplace = True)\n",
    "child_area_df['cnt'] = 1\n",
    "\n",
    "child_area_df['CCTV설치대수'] = child_area_df['CCTV설치대수'].fillna(0)\n",
    "child_area_df['위도'] = child_area_df['위도'].fillna(child_area_df['위도'].mean())\n",
    "child_area_df['경도'] = child_area_df['경도'].fillna(child_area_df['경도'].mean())\n",
    "child_area_df['보호구역도로폭'] = child_area_df['보호구역도로폭'].fillna(child_area_df['보호구역도로폭'].mode()[0])\n",
    "\n",
    "location_pattern = r'(\\S+) (\\S+) (\\S+) (\\S+)'\n",
    "\n",
    "child_area_df[['도시', '구', '동', '번지']] = child_area_df['소재지지번주소'].str.extract(location_pattern)\n",
    "\n",
    "child_area_df.loc[child_area_df['도시'].isna(), '도시'] = \"대구광역시\"\n",
    "child_area_df.loc[child_area_df['구'].isna(), '구'] = \"서구\"\n",
    "child_area_df.loc[child_area_df['동'].isna(), '동'] = \"원대동3가\"\n",
    "\n",
    "child_area_df = child_area_df.drop(columns=['소재지지번주소', '번지'])\n",
    "\n",
    "child_area_df['도로폭_min'] = 0\n",
    "child_area_df.loc[child_area_df['보호구역도로폭'].str.contains(\"~\"), \"도로폭_min\"] = child_area_df.loc[child_area_df['보호구역도로폭'].str.contains(\"~\"), \"보호구역도로폭\"].apply(lambda x : float(x.split(\"~\")[0]))\n",
    "child_area_df.loc[~child_area_df['보호구역도로폭'].str.contains(\"~\"), \"도로폭_min\"] = child_area_df.loc[~child_area_df['보호구역도로폭'].str.contains(\"~\"), \"보호구역도로폭\"].astype(float)\n",
    "\n",
    "child_area_df['도로폭_max'] = 0\n",
    "child_area_df.loc[child_area_df['보호구역도로폭'].str.contains(\"~\"), \"도로폭_max\"] = child_area_df.loc[child_area_df['보호구역도로폭'].str.contains(\"~\"), \"보호구역도로폭\"].apply(lambda x : float(x.split(\"~\")[-1]))\n",
    "child_area_df.loc[~child_area_df['보호구역도로폭'].str.contains(\"~\"), \"도로폭_max\"] = child_area_df.loc[~child_area_df['보호구역도로폭'].str.contains(\"~\"), \"보호구역도로폭\"].astype(float)\n",
    "\n",
    "child_area_df['도로폭_mean'] = (child_area_df['도로폭_min'] + child_area_df['도로폭_max']) / 2\n",
    "\n",
    "#어린이보호구역 동이름 재지정\n",
    "child_area_df.loc[child_area_df['동']==\"옥포면\", \"동\"] = \"옥포읍\"\n",
    "child_area_df.loc[child_area_df['동']==\"현풍면\", \"동\"] = \"현풍읍\"\n",
    "\n",
    "child_area_df_1 = child_area_df[['도시', '구', '동', 'CCTV설치대수']].groupby(['도시', '구', '동']).sum().reset_index()\n",
    "child_area_df_1.reset_index(inplace=True, drop=True)\n",
    "child_area_df_1.rename(columns = {'CCTV설치대수':'어린이보호구역_CCTV총설치대수'}, inplace = True)\n",
    "\n",
    "child_area_df_2 = child_area_df[['도시', '구', '동', 'CCTV설치대수']].groupby(['도시', '구', '동']).mean().reset_index()\n",
    "child_area_df_2.reset_index(inplace=True, drop=True)\n",
    "child_area_df_2.rename(columns = {'CCTV설치대수':'어린이보호구역_CCTV평균설치대수'}, inplace = True)\n",
    "\n",
    "child_area_df_3 = child_area_df[['도시', '구', '동', 'CCTV설치대수']].groupby(['도시', '구', '동']).min().reset_index()\n",
    "child_area_df_3.reset_index(inplace=True, drop=True)\n",
    "child_area_df_3.rename(columns = {'CCTV설치대수':'어린이보호구역_CCTV최소설치대수'}, inplace = True)\n",
    "\n",
    "child_area_df_4 = child_area_df[['도시', '구', '동', 'CCTV설치대수']].groupby(['도시', '구', '동']).max().reset_index()\n",
    "child_area_df_4.reset_index(inplace=True, drop=True)\n",
    "child_area_df_4.rename(columns = {'CCTV설치대수':'어린이보호구역_CCTV최대설치대수'}, inplace = True)\n",
    "\n",
    "child_area_df_5 = child_area_df[['도시', '구', '동', '위도']].groupby(['도시', '구', '동']).min().reset_index()\n",
    "child_area_df_5.reset_index(inplace=True, drop=True)\n",
    "child_area_df_5.rename(columns = {'위도':'어린이보호구역_최저위도'}, inplace = True)\n",
    "\n",
    "child_area_df_6 = child_area_df[['도시', '구', '동', '위도']].groupby(['도시', '구', '동']).mean().reset_index()\n",
    "child_area_df_6.reset_index(inplace=True, drop=True)\n",
    "child_area_df_6.rename(columns = {'위도':'어린이보호구역_평균위도'}, inplace = True)\n",
    "\n",
    "child_area_df_7 = child_area_df[['도시', '구', '동', '위도']].groupby(['도시', '구', '동']).max().reset_index()\n",
    "child_area_df_7.reset_index(inplace=True, drop=True)\n",
    "child_area_df_7.rename(columns = {'위도':'어린이보호구역_최고위도'}, inplace = True)\n",
    "\n",
    "child_area_df_8 = child_area_df[['도시', '구', '동', '경도']].groupby(['도시', '구', '동']).min().reset_index()\n",
    "child_area_df_8.reset_index(inplace=True, drop=True)\n",
    "child_area_df_8.rename(columns = {'경도':'어린이보호구역_최저경도'}, inplace = True)\n",
    "\n",
    "child_area_df_9 = child_area_df[['도시', '구', '동', '경도']].groupby(['도시', '구', '동']).mean().reset_index()\n",
    "child_area_df_9.reset_index(inplace=True, drop=True)\n",
    "child_area_df_9.rename(columns = {'경도':'어린이보호구역_평균경도'}, inplace = True)\n",
    "\n",
    "child_area_df_10 = child_area_df[['도시', '구', '동', '경도']].groupby(['도시', '구', '동']).max().reset_index()\n",
    "child_area_df_10.reset_index(inplace=True, drop=True)\n",
    "child_area_df_10.rename(columns = {'경도':'어린이보호구역_최고경도'}, inplace = True)\n",
    "\n",
    "child_area_df_11 = child_area_df[['도시', '구', '동', '도로폭_min']].groupby(['도시', '구', '동']).mean().reset_index()\n",
    "child_area_df_11.reset_index(inplace=True, drop=True)\n",
    "child_area_df_11.rename(columns = {'도로폭_min':'어린이보호구역_평균최소도로폭'}, inplace = True)\n",
    "\n",
    "child_area_df_12 = child_area_df[['도시', '구', '동', '도로폭_mean']].groupby(['도시', '구', '동']).mean().reset_index()\n",
    "child_area_df_12.reset_index(inplace=True, drop=True)\n",
    "child_area_df_12.rename(columns = {'도로폭_mean':'어린이보호구역_평균도로폭'}, inplace = True)\n",
    "\n",
    "child_area_df_13 = child_area_df[['도시', '구', '동', '도로폭_max']].groupby(['도시', '구', '동']).mean().reset_index()\n",
    "child_area_df_13.reset_index(inplace=True, drop=True)\n",
    "child_area_df_13.rename(columns = {'도로폭_max':'어린이보호구역_평균최대도로폭'}, inplace = True)\n",
    "\n",
    "child_area_df_14 = child_area_df[['도시', '구', '동', 'cnt']].groupby(['도시', '구', '동']).sum().reset_index()\n",
    "child_area_df_14.reset_index(inplace=True, drop=True)\n",
    "child_area_df_14.rename(columns = {'cnt':'어린이보호구역_총개수'}, inplace = True)\n",
    "\n",
    "child_area_df = pd.merge(child_area_df_1, child_area_df_2, how='left', on=['도시', '구', '동'])\n",
    "child_area_df = pd.merge(child_area_df, child_area_df_3, how='left', on=['도시', '구', '동'])\n",
    "child_area_df = pd.merge(child_area_df, child_area_df_4, how='left', on=['도시', '구', '동'])\n",
    "child_area_df = pd.merge(child_area_df, child_area_df_5, how='left', on=['도시', '구', '동'])\n",
    "child_area_df = pd.merge(child_area_df, child_area_df_6, how='left', on=['도시', '구', '동'])\n",
    "child_area_df = pd.merge(child_area_df, child_area_df_7, how='left', on=['도시', '구', '동'])\n",
    "child_area_df = pd.merge(child_area_df, child_area_df_8, how='left', on=['도시', '구', '동'])\n",
    "child_area_df = pd.merge(child_area_df, child_area_df_9, how='left', on=['도시', '구', '동'])\n",
    "child_area_df = pd.merge(child_area_df, child_area_df_10, how='left', on=['도시', '구', '동'])\n",
    "child_area_df = pd.merge(child_area_df, child_area_df_11, how='left', on=['도시', '구', '동'])\n",
    "child_area_df = pd.merge(child_area_df, child_area_df_12, how='left', on=['도시', '구', '동'])\n",
    "child_area_df = pd.merge(child_area_df, child_area_df_13, how='left', on=['도시', '구', '동'])\n",
    "child_area_df = pd.merge(child_area_df, child_area_df_14, how='left', on=['도시', '구', '동'])\n",
    "\n",
    "child_area_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Pi4V4pvXZiS"
   },
   "outputs": [],
   "source": [
    "#주차장 데이터\n",
    "parking_df = pd.read_csv('/content/drive/MyDrive/대구_교통사고_피해_예측_AI경진대회/open/data/대구 주차장 정보.csv', encoding='cp949').drop_duplicates()[['소재지지번주소', '주차구획수', '위도', '경도', '급지구분']]\n",
    "parking_df.dropna(subset = ['소재지지번주소'], inplace = True)\n",
    "parking_df = pd.get_dummies(parking_df, columns=['급지구분'])\n",
    "parking_df['cnt'] = 1\n",
    "\n",
    "parking_df['위도'] = parking_df['위도'].fillna(parking_df['위도'].mean())\n",
    "parking_df['경도'] = parking_df['경도'].fillna(parking_df['경도'].mean())\n",
    "\n",
    "location_pattern = r'(\\S+) (\\S+) (\\S+) (\\S+)'\n",
    "\n",
    "parking_df[['도시', '구', '동', '번지']] = parking_df['소재지지번주소'].str.extract(location_pattern)\n",
    "\n",
    "location_pattern = r'(\\S+) (\\S+) (\\S+)'\n",
    "\n",
    "parking_df.loc[parking_df['도시'].isna(), '도시'] = parking_df.loc[parking_df['도시'].isna(), '소재지지번주소'].str.extract(location_pattern).iloc[:,0]\n",
    "parking_df.loc[parking_df['구'].isna(), '구'] = parking_df.loc[parking_df['구'].isna(), '소재지지번주소'].str.extract(location_pattern).iloc[:,1]\n",
    "parking_df.loc[parking_df['동'].isna(), '동'] = parking_df.loc[parking_df['동'].isna(), '소재지지번주소'].str.extract(location_pattern).iloc[:,2]\n",
    "\n",
    "parking_df.loc[parking_df['동'].str.contains(\"-\"), '동'] = parking_df.loc[parking_df['동'].str.contains(\"-\"), '동'].apply(lambda x : re.sub(r'\\d+-\\d+', '', x))\n",
    "\n",
    "parking_df = parking_df.drop(columns=['소재지지번주소', '번지'])\n",
    "\n",
    "#주차장 동이름 재지정\n",
    "parking_df.loc[parking_df['동']==\"옥포면\", \"동\"] = \"옥포읍\"\n",
    "parking_df.loc[parking_df['동']==\"현풍면\", \"동\"] = \"현풍읍\"\n",
    "parking_df.loc[parking_df['동']==\"내당4동\", \"동\"] = \"내당동\"\n",
    "parking_df.loc[parking_df['동']==\"유곡리\", \"동\"] = \"유가읍\"\n",
    "\n",
    "parking_df_1 = parking_df[['도시', '구', '동', '주차구획수']].groupby(['도시', '구', '동']).mean().reset_index()\n",
    "parking_df_1.reset_index(inplace=True, drop=True)\n",
    "parking_df_1.rename(columns = {'주차구획수':'주차장_평균주차구획수'}, inplace = True)\n",
    "\n",
    "parking_df_2 = parking_df[['도시', '구', '동', '주차구획수']].groupby(['도시', '구', '동']).min().reset_index()\n",
    "parking_df_2.reset_index(inplace=True, drop=True)\n",
    "parking_df_2.rename(columns = {'주차구획수':'주차장_최소주차구획수'}, inplace = True)\n",
    "\n",
    "parking_df_3 = parking_df[['도시', '구', '동', '주차구획수']].groupby(['도시', '구', '동']).max().reset_index()\n",
    "parking_df_3.reset_index(inplace=True, drop=True)\n",
    "parking_df_3.rename(columns = {'주차구획수':'주차장_최대주차구획수'}, inplace = True)\n",
    "\n",
    "parking_df_4 = parking_df[['도시', '구', '동', '주차구획수']].groupby(['도시', '구', '동']).sum().reset_index()\n",
    "parking_df_4.reset_index(inplace=True, drop=True)\n",
    "parking_df_4.rename(columns = {'주차구획수':'주차장_총주차구획수'}, inplace = True)\n",
    "\n",
    "parking_df_5 = parking_df[['도시', '구', '동', '위도']].groupby(['도시', '구', '동']).min().reset_index()\n",
    "parking_df_5.reset_index(inplace=True, drop=True)\n",
    "parking_df_5.rename(columns = {'위도':'주차장_최저위도'}, inplace = True)\n",
    "\n",
    "parking_df_6 = parking_df[['도시', '구', '동', '위도']].groupby(['도시', '구', '동']).mean().reset_index()\n",
    "parking_df_6.reset_index(inplace=True, drop=True)\n",
    "parking_df_6.rename(columns = {'위도':'주차장_평균위도'}, inplace = True)\n",
    "\n",
    "parking_df_7 = parking_df[['도시', '구', '동', '위도']].groupby(['도시', '구', '동']).max().reset_index()\n",
    "parking_df_7.reset_index(inplace=True, drop=True)\n",
    "parking_df_7.rename(columns = {'위도':'주차장_최고위도'}, inplace = True)\n",
    "\n",
    "parking_df_8 = parking_df[['도시', '구', '동', '경도']].groupby(['도시', '구', '동']).min().reset_index()\n",
    "parking_df_8.reset_index(inplace=True, drop=True)\n",
    "parking_df_8.rename(columns = {'경도':'주차장_최저경도'}, inplace = True)\n",
    "\n",
    "parking_df_9 = parking_df[['도시', '구', '동', '경도']].groupby(['도시', '구', '동']).mean().reset_index()\n",
    "parking_df_9.reset_index(inplace=True, drop=True)\n",
    "parking_df_9.rename(columns = {'경도':'주차장_평균경도'}, inplace = True)\n",
    "\n",
    "parking_df_10 = parking_df[['도시', '구', '동', '경도']].groupby(['도시', '구', '동']).max().reset_index()\n",
    "parking_df_10.reset_index(inplace=True, drop=True)\n",
    "parking_df_10.rename(columns = {'경도':'주차장_최고경도'}, inplace = True)\n",
    "\n",
    "parking_df_11 = parking_df[['도시', '구', '동', '급지구분_1']].groupby(['도시', '구', '동']).sum().reset_index()\n",
    "parking_df_11.reset_index(inplace=True, drop=True)\n",
    "parking_df_11.rename(columns = {'급지구분_1':'주차장_급지구분합계_1'}, inplace = True)\n",
    "\n",
    "parking_df_12 = parking_df[['도시', '구', '동', '급지구분_2']].groupby(['도시', '구', '동']).sum().reset_index()\n",
    "parking_df_12.reset_index(inplace=True, drop=True)\n",
    "parking_df_12.rename(columns = {'급지구분_2':'주차장_급지구분합계_2'}, inplace = True)\n",
    "\n",
    "parking_df_13 = parking_df[['도시', '구', '동', '급지구분_3']].groupby(['도시', '구', '동']).sum().reset_index()\n",
    "parking_df_13.reset_index(inplace=True, drop=True)\n",
    "parking_df_13.rename(columns = {'급지구분_3':'주차장_급지구분합계_3'}, inplace = True)\n",
    "\n",
    "parking_df_14 = parking_df[['도시', '구', '동', 'cnt']].groupby(['도시', '구', '동']).sum().reset_index()\n",
    "parking_df_14.reset_index(inplace=True, drop=True)\n",
    "parking_df_14.rename(columns = {'cnt':'주차장_총개수'}, inplace = True)\n",
    "\n",
    "parking_df = pd.merge(parking_df_1, parking_df_2, how='left', on=['도시', '구', '동'])\n",
    "parking_df = pd.merge(parking_df, parking_df_3, how='left', on=['도시', '구', '동'])\n",
    "parking_df = pd.merge(parking_df, parking_df_4, how='left', on=['도시', '구', '동'])\n",
    "parking_df = pd.merge(parking_df, parking_df_5, how='left', on=['도시', '구', '동'])\n",
    "parking_df = pd.merge(parking_df, parking_df_6, how='left', on=['도시', '구', '동'])\n",
    "parking_df = pd.merge(parking_df, parking_df_7, how='left', on=['도시', '구', '동'])\n",
    "parking_df = pd.merge(parking_df, parking_df_8, how='left', on=['도시', '구', '동'])\n",
    "parking_df = pd.merge(parking_df, parking_df_9, how='left', on=['도시', '구', '동'])\n",
    "parking_df = pd.merge(parking_df, parking_df_10, how='left', on=['도시', '구', '동'])\n",
    "parking_df = pd.merge(parking_df, parking_df_11, how='left', on=['도시', '구', '동'])\n",
    "parking_df = pd.merge(parking_df, parking_df_12, how='left', on=['도시', '구', '동'])\n",
    "parking_df = pd.merge(parking_df, parking_df_13, how='left', on=['도시', '구', '동'])\n",
    "parking_df = pd.merge(parking_df, parking_df_14, how='left', on=['도시', '구', '동'])\n",
    "\n",
    "parking_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2A4VhK1QXZiS"
   },
   "outputs": [],
   "source": [
    "#cctv 데이터\n",
    "cctv_df = pd.read_csv('/content/drive/MyDrive/대구_교통사고_피해_예측_AI경진대회/open/data/대구 CCTV 정보.csv', encoding='cp949').drop_duplicates()[['소재지지번주소', '단속구분', '제한속도', '위도', '경도', '설치연도']]\n",
    "cctv_df.dropna(subset = ['소재지지번주소'], inplace = True)\n",
    "cctv_df['설치연도'] = cctv_df['설치연도'].fillna(cctv_df['설치연도'].mode()[0])\n",
    "cctv_df = pd.get_dummies(cctv_df, columns=['단속구분'])\n",
    "cctv_df['cnt'] = 1\n",
    "\n",
    "location_pattern = r'(\\S+) (\\S+) (\\S+) (\\S+)'\n",
    "\n",
    "cctv_df[['도시', '구', '동', '번지']] = cctv_df['소재지지번주소'].str.extract(location_pattern)\n",
    "\n",
    "location_pattern = r'(\\S+) (\\S+) (\\S+)'\n",
    "\n",
    "cctv_df.loc[cctv_df['도시'].isna(), '도시'] = cctv_df.loc[cctv_df['도시'].isna(), '소재지지번주소'].str.extract(location_pattern).iloc[:,0]\n",
    "cctv_df.loc[cctv_df['구'].isna(), '구'] = cctv_df.loc[cctv_df['구'].isna(), '소재지지번주소'].str.extract(location_pattern).iloc[:,1]\n",
    "cctv_df.loc[cctv_df['동'].isna(), '동'] = cctv_df.loc[cctv_df['동'].isna(), '소재지지번주소'].str.extract(location_pattern).iloc[:,2]\n",
    "\n",
    "cctv_df.loc[cctv_df['동'].str.contains(\"-\"), '동'] = cctv_df.loc[cctv_df['동'].str.contains(\"-\"), '동'].apply(lambda x : re.sub(r'\\d+-\\d+', '', x))\n",
    "\n",
    "cctv_df['도시'] = cctv_df['도시'].map({'대구':'대구광역시','대구광역시':'대구광역시'})\n",
    "\n",
    "cctv_df.loc[cctv_df['구'] == \"가창면\", \"구\"] = \"달성군\"\n",
    "cctv_df.loc[cctv_df['동'] == \"삼산리\", \"동\"] = \"가창면\"\n",
    "cctv_df.loc[cctv_df['구'] == \"다사읍\", \"구\"] = \"달성군\"\n",
    "cctv_df.loc[cctv_df['동'] == \"세천리\", \"동\"] = \"다사읍\"\n",
    "\n",
    "cctv_df = cctv_df.drop(columns=['소재지지번주소', '번지'])\n",
    "\n",
    "#cctv 동이름 그룹핑\n",
    "cctv_df.loc[cctv_df['동']==\"남리\", \"동\"] = \"논공읍\"\n",
    "cctv_df.loc[cctv_df['동']==\"두류1동\", \"동\"] = \"두류동\"\n",
    "cctv_df.loc[cctv_df['동']==\"두류2동\", \"동\"] = \"두류동\"\n",
    "cctv_df.loc[cctv_df['동']==\"매곡리\", \"동\"] = \"다사읍\"\n",
    "cctv_df.loc[cctv_df['동']==\"북리\", \"동\"] = \"논공읍\"\n",
    "cctv_df.loc[cctv_df['동']==\"비산2.3동\", \"동\"] = \"비산동\"\n",
    "cctv_df.loc[cctv_df['동']==\"비산4동\", \"동\"] = \"비산동\"\n",
    "cctv_df.loc[cctv_df['동']==\"신암1동\", \"동\"] = \"신암동\"\n",
    "cctv_df.loc[cctv_df['동']==\"신암4동\", \"동\"] = \"신암동\"\n",
    "cctv_df.loc[cctv_df['동']==\"용계리\", \"동\"] = \"가창면\"\n",
    "cctv_df.loc[cctv_df['동']==\"정대리\", \"동\"] = \"가창면\"\n",
    "cctv_df.loc[cctv_df['동']==\"유가면\", \"동\"] = \"유가읍\"\n",
    "cctv_df.loc[cctv_df['동']==\"침산2동\", \"동\"] = \"침산동\"\n",
    "cctv_df.loc[cctv_df['동']==\"평리2동\", \"동\"] = \"평리동\"\n",
    "cctv_df.loc[cctv_df['동']==\"하리\", \"동\"] = \"논공읍\"\n",
    "cctv_df.loc[cctv_df['동']==\"현풍면\", \"동\"] = \"현풍읍\"\n",
    "\n",
    "cctv_df_1 = cctv_df[['도시', '구', '동', '단속구분_1']].groupby(['도시', '구', '동']).sum().reset_index()\n",
    "cctv_df_1.reset_index(inplace=True, drop=True)\n",
    "cctv_df_1.rename(columns = {'단속구분_1':'cctv_총단속구분_1'}, inplace = True)\n",
    "\n",
    "cctv_df_2 = cctv_df[['도시', '구', '동', '단속구분_2']].groupby(['도시', '구', '동']).sum().reset_index()\n",
    "cctv_df_2.reset_index(inplace=True, drop=True)\n",
    "cctv_df_2.rename(columns = {'단속구분_2':'cctv_총단속구분_2'}, inplace = True)\n",
    "\n",
    "cctv_df_3 = cctv_df[['도시', '구', '동', '단속구분_4']].groupby(['도시', '구', '동']).sum().reset_index()\n",
    "cctv_df_3.reset_index(inplace=True, drop=True)\n",
    "cctv_df_3.rename(columns = {'단속구분_4':'cctv_총단속구분_4'}, inplace = True)\n",
    "\n",
    "cctv_df_4 = cctv_df[['도시', '구', '동', '단속구분_99']].groupby(['도시', '구', '동']).sum().reset_index()\n",
    "cctv_df_4.reset_index(inplace=True, drop=True)\n",
    "cctv_df_4.rename(columns = {'단속구분_99':'cctv_총단속구분_99'}, inplace = True)\n",
    "\n",
    "cctv_df_5 = cctv_df[['도시', '구', '동', '제한속도']].groupby(['도시', '구', '동']).min().reset_index()\n",
    "cctv_df_5.reset_index(inplace=True, drop=True)\n",
    "cctv_df_5.rename(columns = {'제한속도':'cctv_최소제한속도'}, inplace = True)\n",
    "\n",
    "cctv_df_6 = cctv_df[['도시', '구', '동', '제한속도']].groupby(['도시', '구', '동']).mean().reset_index()\n",
    "cctv_df_6.reset_index(inplace=True, drop=True)\n",
    "cctv_df_6.rename(columns = {'제한속도':'cctv_평균제한속도'}, inplace = True)\n",
    "\n",
    "cctv_df_7 = cctv_df[['도시', '구', '동', '제한속도']].groupby(['도시', '구', '동']).max().reset_index()\n",
    "cctv_df_7.reset_index(inplace=True, drop=True)\n",
    "cctv_df_7.rename(columns = {'제한속도':'cctv_최대제한속도'}, inplace = True)\n",
    "\n",
    "cctv_df_8 = cctv_df[['도시', '구', '동', '제한속도']].groupby(['도시', '구', '동']).median().reset_index()\n",
    "cctv_df_8.reset_index(inplace=True, drop=True)\n",
    "cctv_df_8.rename(columns = {'제한속도':'cctv_중간제한속도'}, inplace = True)\n",
    "\n",
    "cctv_df_9 = cctv_df[['도시', '구', '동', '위도']].groupby(['도시', '구', '동']).min().reset_index()\n",
    "cctv_df_9.reset_index(inplace=True, drop=True)\n",
    "cctv_df_9.rename(columns = {'위도':'cctv_최저위도'}, inplace = True)\n",
    "\n",
    "cctv_df_10 = cctv_df[['도시', '구', '동', '위도']].groupby(['도시', '구', '동']).mean().reset_index()\n",
    "cctv_df_10.reset_index(inplace=True, drop=True)\n",
    "cctv_df_10.rename(columns = {'위도':'cctv_평균위도'}, inplace = True)\n",
    "\n",
    "cctv_df_11 = cctv_df[['도시', '구', '동', '위도']].groupby(['도시', '구', '동']).max().reset_index()\n",
    "cctv_df_11.reset_index(inplace=True, drop=True)\n",
    "cctv_df_11.rename(columns = {'위도':'cctv_최고위도'}, inplace = True)\n",
    "\n",
    "cctv_df_12 = cctv_df[['도시', '구', '동', '경도']].groupby(['도시', '구', '동']).min().reset_index()\n",
    "cctv_df_12.reset_index(inplace=True, drop=True)\n",
    "cctv_df_12.rename(columns = {'경도':'cctv_최저경도'}, inplace = True)\n",
    "\n",
    "cctv_df_13 = cctv_df[['도시', '구', '동', '경도']].groupby(['도시', '구', '동']).mean().reset_index()\n",
    "cctv_df_13.reset_index(inplace=True, drop=True)\n",
    "cctv_df_13.rename(columns = {'경도':'cctv_평균경도'}, inplace = True)\n",
    "\n",
    "cctv_df_14 = cctv_df[['도시', '구', '동', '경도']].groupby(['도시', '구', '동']).max().reset_index()\n",
    "cctv_df_14.reset_index(inplace=True, drop=True)\n",
    "cctv_df_14.rename(columns = {'경도':'cctv_최고경도'}, inplace = True)\n",
    "\n",
    "cctv_df_15 = cctv_df[['도시', '구', '동', '설치연도']].groupby(['도시', '구', '동']).mean().reset_index()\n",
    "cctv_df_15.reset_index(inplace=True, drop=True)\n",
    "cctv_df_15.rename(columns = {'설치연도':'cctv_평균설치연도'}, inplace = True)\n",
    "\n",
    "cctv_df_16 = cctv_df[['도시', '구', '동', '설치연도']].groupby(['도시', '구', '동']).min().reset_index()\n",
    "cctv_df_16.reset_index(inplace=True, drop=True)\n",
    "cctv_df_16.rename(columns = {'설치연도':'cctv_최소설치연도'}, inplace = True)\n",
    "\n",
    "cctv_df_17 = cctv_df[['도시', '구', '동', '설치연도']].groupby(['도시', '구', '동']).max().reset_index()\n",
    "cctv_df_17.reset_index(inplace=True, drop=True)\n",
    "cctv_df_17.rename(columns = {'설치연도':'cctv_최대설치연도'}, inplace = True)\n",
    "\n",
    "cctv_df_18 = cctv_df[['도시', '구', '동', 'cnt']].groupby(['도시', '구', '동']).sum().reset_index()\n",
    "cctv_df_18.reset_index(inplace=True, drop=True)\n",
    "cctv_df_18.rename(columns = {'cnt':'cctv_총개수'}, inplace = True)\n",
    "\n",
    "cctv_df = pd.merge(cctv_df_1, cctv_df_2, how='left', on=['도시', '구', '동'])\n",
    "cctv_df = pd.merge(cctv_df, cctv_df_3, how='left', on=['도시', '구', '동'])\n",
    "cctv_df = pd.merge(cctv_df, cctv_df_4, how='left', on=['도시', '구', '동'])\n",
    "cctv_df = pd.merge(cctv_df, cctv_df_5, how='left', on=['도시', '구', '동'])\n",
    "cctv_df = pd.merge(cctv_df, cctv_df_6, how='left', on=['도시', '구', '동'])\n",
    "cctv_df = pd.merge(cctv_df, cctv_df_7, how='left', on=['도시', '구', '동'])\n",
    "cctv_df = pd.merge(cctv_df, cctv_df_8, how='left', on=['도시', '구', '동'])\n",
    "cctv_df = pd.merge(cctv_df, cctv_df_9, how='left', on=['도시', '구', '동'])\n",
    "cctv_df = pd.merge(cctv_df, cctv_df_10, how='left', on=['도시', '구', '동'])\n",
    "cctv_df = pd.merge(cctv_df, cctv_df_11, how='left', on=['도시', '구', '동'])\n",
    "cctv_df = pd.merge(cctv_df, cctv_df_12, how='left', on=['도시', '구', '동'])\n",
    "cctv_df = pd.merge(cctv_df, cctv_df_13, how='left', on=['도시', '구', '동'])\n",
    "cctv_df = pd.merge(cctv_df, cctv_df_14, how='left', on=['도시', '구', '동'])\n",
    "cctv_df = pd.merge(cctv_df, cctv_df_15, how='left', on=['도시', '구', '동'])\n",
    "cctv_df = pd.merge(cctv_df, cctv_df_16, how='left', on=['도시', '구', '동'])\n",
    "cctv_df = pd.merge(cctv_df, cctv_df_17, how='left', on=['도시', '구', '동'])\n",
    "cctv_df = pd.merge(cctv_df, cctv_df_18, how='left', on=['도시', '구', '동'])\n",
    "\n",
    "cctv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVF3BeUzXZiT"
   },
   "source": [
    "### 1-2. Train, Test, Countrywide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "QT3np4IgXZiT"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/content/drive/MyDrive/대구_교통사고_피해_예측_AI경진대회/open/train.csv\")\n",
    "test_df = pd.read_csv(\"/content/drive/MyDrive/대구_교통사고_피해_예측_AI경진대회/open/test.csv\")\n",
    "country_wide = pd.read_csv(\"/content/drive/MyDrive/대구_교통사고_피해_예측_AI경진대회/open/data/countrywide_accident.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "cPdvfFRCpSRJ"
   },
   "outputs": [],
   "source": [
    "train_df['ECLO'] = train_df['사망자수'] * 10 + train_df['중상자수'] * 5 + train_df['경상자수'] * 3 + train_df['부상자수'] * 1\n",
    "country_wide['ECLO'] = country_wide['사망자수'] * 10 + country_wide['중상자수'] * 5 + country_wide['경상자수'] * 3 + country_wide['부상자수'] * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqN-LXxhXZiT"
   },
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "EMAGfVcmXZiT"
   },
   "outputs": [],
   "source": [
    "#test 추론시점에서는 알 수 없는 정보들 drop\n",
    "drop_cols = ['사고유형 - 세부분류', '법규위반', '가해운전자 차종', '가해운전자 성별', '가해운전자 연령', '가해운전자 상해정도', '피해운전자 차종', '피해운전자 성별', '피해운전자 연령', '피해운전자 상해정도']\n",
    "train_df.drop(columns = drop_cols, inplace = True)\n",
    "country_wide.drop(columns = drop_cols, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "c6mAKyY_XZiT"
   },
   "outputs": [],
   "source": [
    "train_df['사고일시'] = pd.to_datetime(train_df['사고일시'])\n",
    "test_df['사고일시'] = pd.to_datetime(test_df['사고일시'])\n",
    "country_wide['사고일시'] = pd.to_datetime(country_wide['사고일시'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "4csklvNSXZiU"
   },
   "outputs": [],
   "source": [
    "for df in [train_df, test_df, country_wide]:\n",
    "    df['연'] = df['사고일시'].dt.year\n",
    "    df['월'] = df['사고일시'].dt.month\n",
    "    df['일'] = df['사고일시'].dt.day\n",
    "    df['monthday'] = df.apply(lambda row: str(row['월']) + '-' + str(row['일']), axis=1)\n",
    "    df['시간'] = df['사고일시'].dt.hour\n",
    "    df['weekday'] = df['사고일시'].dt.weekday\n",
    "    df['weekofyear'] = (df['사고일시'].dt.isocalendar().week).astype(int)\n",
    "    df['새벽'] = df['시간'].isin([0,1,2,3,4,5,6]).astype(int)\n",
    "    df['밤'] = df['시간'].isin([21,22,23]).astype(int)\n",
    "    df['주말'] = df['weekday'].isin([5,6]).astype(int)\n",
    "    df['주중'] = df['weekday'].isin([0,1,2,3,4]).astype(int)\n",
    "    df['국가공휴일_상준'] = df['monthday'].isin(['1-1','3-1','5-5','6-6','8-15','10-3','10-9','12-25','12-31']).astype(int)\n",
    "\n",
    "\n",
    "train_df = train_df.drop(columns=['사고일시','monthday']) # 정보 추출이 완료된 '사고일시' 컬럼은 제거합니다\n",
    "test_df = test_df.drop(columns=['사고일시','monthday'])\n",
    "country_wide = country_wide.drop(columns=['사고일시','monthday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T12:28:00.101427Z",
     "iopub.status.busy": "2023-11-19T12:28:00.101078Z",
     "iopub.status.idle": "2023-11-19T12:28:00.252709Z",
     "shell.execute_reply": "2023-11-19T12:28:00.251661Z",
     "shell.execute_reply.started": "2023-11-19T12:28:00.101401Z"
    },
    "id": "HkSc1ee6XZiU"
   },
   "outputs": [],
   "source": [
    "#지역 정보 추출\n",
    "location_pattern = r'(\\S+) (\\S+) (\\S+)'\n",
    "\n",
    "train_df[['도시', '구', '동']] = train_df['시군구'].str.extract(location_pattern)\n",
    "train_df = train_df.drop(columns=['시군구'])\n",
    "\n",
    "test_df[['도시', '구', '동']] = test_df['시군구'].str.extract(location_pattern)\n",
    "test_df = test_df.drop(columns=['시군구'])\n",
    "\n",
    "country_wide[['도시', '구', '동']] = country_wide['시군구'].str.extract(location_pattern)\n",
    "\n",
    "location_pattern = r'(\\S+) (\\S+)'\n",
    "\n",
    "country_wide.loc[country_wide['도시'].isna(), '도시'] = country_wide.loc[country_wide['도시'].isna(), '시군구'].str.extract(location_pattern).iloc[:,0]\n",
    "country_wide.loc[country_wide['구'].isna(), '구'] = \"세종특별자치시\"\n",
    "country_wide.loc[country_wide['동'].isna(), '동'] = country_wide.loc[country_wide['동'].isna(), '시군구'].str.extract(location_pattern).iloc[:,1]\n",
    "country_wide = country_wide.drop(columns=['시군구'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T12:28:00.254618Z",
     "iopub.status.busy": "2023-11-19T12:28:00.254152Z",
     "iopub.status.idle": "2023-11-19T12:28:00.409011Z",
     "shell.execute_reply": "2023-11-19T12:28:00.408023Z",
     "shell.execute_reply.started": "2023-11-19T12:28:00.254576Z"
    },
    "id": "1RlcLWXjXZiU"
   },
   "outputs": [],
   "source": [
    "#도로 정보 추출\n",
    "road_pattern = r'(.+) - (.+)'\n",
    "\n",
    "train_df[['도로형태1', '도로형태2']] = train_df['도로형태'].str.extract(road_pattern)\n",
    "train_df = train_df.drop(columns=['도로형태'])\n",
    "\n",
    "test_df[['도로형태1', '도로형태2']] = test_df['도로형태'].str.extract(road_pattern)\n",
    "test_df = test_df.drop(columns=['도로형태'])\n",
    "\n",
    "country_wide[['도로형태1', '도로형태2']] = country_wide['도로형태'].str.extract(road_pattern)\n",
    "country_wide = country_wide.drop(columns=['도로형태'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "lBHdieTcXZiU"
   },
   "outputs": [],
   "source": [
    "train_df['사고유형_도로형태2'] = train_df['사고유형'] + '_' + train_df['도로형태2']\n",
    "test_df['사고유형_도로형태2'] = test_df['사고유형'] + '_' + test_df['도로형태2']\n",
    "country_wide['사고유형_도로형태2'] = country_wide['사고유형'] + '_' + country_wide['도로형태2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "2MgGS0JqXZiU"
   },
   "outputs": [],
   "source": [
    "#대구 추가데이터 preprocessing\n",
    "additional.loc[additional['노면상태']==\"결빙\", \"노면상태\"] = \"서리/결빙\"\n",
    "additional.loc[additional['노면상태']==\"습기\", \"노면상태\"] = \"젖음/습기\"\n",
    "\n",
    "additional.loc[additional['동']==\"논공읍공단출장\", \"동\"] = \"논공읍\"\n",
    "additional.loc[additional['동']==\"다사읍서재출장\", \"동\"] = \"다사읍\"\n",
    "additional.loc[additional['동']==\"옥포면\", \"동\"] = \"옥포읍\"\n",
    "additional.loc[additional['동']==\"유가면\", \"동\"] = \"유가읍\"\n",
    "additional.loc[additional['동']==\"현풍면\", \"동\"] = \"현풍읍\"\n",
    "\n",
    "additional.loc[additional['도로형태2']==\"횡단보도부근\", \"도로형태2\"] = \"교차로횡단보도내\"\n",
    "additional.loc[additional['도로형태2']==\"횡단보도상\", \"도로형태2\"] = \"교차로횡단보도내\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "id": "It5mlBm_XZiV"
   },
   "outputs": [],
   "source": [
    "train_df = pd.concat([additional,train_df], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T12:28:00.412566Z",
     "iopub.status.busy": "2023-11-19T12:28:00.412139Z",
     "iopub.status.idle": "2023-11-19T12:28:00.417983Z",
     "shell.execute_reply": "2023-11-19T12:28:00.416965Z",
     "shell.execute_reply.started": "2023-11-19T12:28:00.412526Z"
    },
    "id": "kFZM-lDtXZiV"
   },
   "outputs": [],
   "source": [
    "#train, test에 외부데이터 merge\n",
    "train_df = pd.merge(train_df, light_df, how='left', on=['도시', '구', '동'])\n",
    "train_df = pd.merge(train_df, child_area_df, how='left', on=['도시', '구', '동'])\n",
    "train_df = pd.merge(train_df, parking_df, how='left', on=['도시', '구', '동'])\n",
    "train_df = pd.merge(train_df, cctv_df, how='left', on=['도시', '구', '동'])\n",
    "\n",
    "test_df = pd.merge(test_df, light_df, how='left', on=['도시', '구', '동'])\n",
    "test_df = pd.merge(test_df, child_area_df, how='left', on=['도시', '구', '동'])\n",
    "test_df = pd.merge(test_df, parking_df, how='left', on=['도시', '구', '동'])\n",
    "test_df = pd.merge(test_df, cctv_df, how='left', on=['도시', '구', '동'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "id": "el8T_hyXXZiV"
   },
   "outputs": [],
   "source": [
    "#country_wide 데이터를 합친 데이터 셋\n",
    "train_org = pd.read_csv(\"/content/drive/MyDrive/대구_교통사고_피해_예측_AI경진대회/open/train.csv\")\n",
    "test_org = pd.read_csv(\"/content/drive/MyDrive/대구_교통사고_피해_예측_AI경진대회/open/test.csv\")\n",
    "\n",
    "train_org['ECLO'] = train_org['사망자수'] * 10 + train_org['중상자수'] * 5 + train_org['경상자수'] * 3 + train_org['부상자수'] * 1\n",
    "\n",
    "train_org.drop(columns = drop_cols, inplace = True)\n",
    "train_org['사고일시'] = pd.to_datetime(train_org['사고일시'])\n",
    "test_org['사고일시'] = pd.to_datetime(test_org['사고일시'])\n",
    "\n",
    "for df in [train_org]:\n",
    "    df['연'] = df['사고일시'].dt.year\n",
    "    df['월'] = df['사고일시'].dt.month\n",
    "    df['일'] = df['사고일시'].dt.day\n",
    "    df['monthday'] = df.apply(lambda row: str(row['월']) + '-' + str(row['일']), axis=1)\n",
    "    df['시간'] = df['사고일시'].dt.hour\n",
    "    df['weekday'] = df['사고일시'].dt.weekday\n",
    "    df['weekofyear'] = (df['사고일시'].dt.isocalendar().week).astype(int)\n",
    "\n",
    "    df['새벽'] = df['시간'].isin([0,1,2,3,4,5,6]).astype(int)\n",
    "    df['밤'] = df['시간'].isin([21,22,23]).astype(int)\n",
    "    df['주말'] = df['weekday'].isin([5,6]).astype(int)\n",
    "    df['주중'] = df['weekday'].isin([0,1,2,3,4]).astype(int)\n",
    "    df['국가공휴일_상준'] = df['monthday'].isin(['1-1','3-1','5-5','6-6','8-15','10-3','10-9','12-25','12-31']).astype(int)\n",
    "\n",
    "train_org = train_org.drop(columns=['사고일시','monthday'])\n",
    "\n",
    "location_pattern = r'(\\S+) (\\S+) (\\S+)'\n",
    "\n",
    "train_org[['도시', '구', '동']] = train_org['시군구'].str.extract(location_pattern)\n",
    "train_org = train_org.drop(columns=['시군구'])\n",
    "\n",
    "train_org[['도로형태1', '도로형태2']] = train_org['도로형태'].str.extract(road_pattern)\n",
    "train_org = train_org.drop(columns=['도로형태'])\n",
    "\n",
    "train_org['사고유형_도로형태2'] = train_org['사고유형'] + '_' + train_org['도로형태2']\n",
    "\n",
    "train_large = pd.concat([train_org,country_wide], axis = 0).reset_index(drop=True)\n",
    "\n",
    "for df in [test_org]:\n",
    "    df['연'] = df['사고일시'].dt.year\n",
    "    df['월'] = df['사고일시'].dt.month\n",
    "    df['일'] = df['사고일시'].dt.day\n",
    "    df['monthday'] = df.apply(lambda row: str(row['월']) + '-' + str(row['일']), axis=1)\n",
    "    df['시간'] = df['사고일시'].dt.hour\n",
    "    df['weekday'] = df['사고일시'].dt.weekday\n",
    "    df['weekofyear'] = (df['사고일시'].dt.isocalendar().week).astype(int)\n",
    "\n",
    "    df['새벽'] = df['시간'].isin([0,1,2,3,4,5,6]).astype(int)\n",
    "    df['밤'] = df['시간'].isin([21,22,23]).astype(int)\n",
    "    df['주말'] = df['weekday'].isin([5,6]).astype(int)\n",
    "    df['주중'] = df['weekday'].isin([0,1,2,3,4]).astype(int)\n",
    "    df['국가공휴일_상준'] = df['monthday'].isin(['1-1','3-1','5-5','6-6','8-15','10-3','10-9','12-25','12-31']).astype(int)\n",
    "\n",
    "test_org = test_org.drop(columns=['사고일시','monthday'])\n",
    "\n",
    "test_org[['도시', '구', '동']] = test_org['시군구'].str.extract(location_pattern)\n",
    "test_org = test_org.drop(columns=['시군구'])\n",
    "\n",
    "test_org[['도로형태1', '도로형태2']] = test_org['도로형태'].str.extract(road_pattern)\n",
    "test_org = test_org.drop(columns=['도로형태'])\n",
    "\n",
    "test_org['사고유형_도로형태2'] = test_org['사고유형'] + '_' + test_org['도로형태2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "AF73y_o1XZiV"
   },
   "outputs": [],
   "source": [
    "#겹치는 구 및 동 처리\n",
    "train_large['new_구'] = train_large['도시'] + '_' + train_large['구']\n",
    "test_org['new_구'] = test_org['도시'] + '_' + test_org['구']\n",
    "\n",
    "train_large['new_동'] = train_large['도시'] + '_' + train_large['구'] + '_' + train_large['동']\n",
    "test_org['new_동'] = test_org['도시'] + '_' + test_org['구'] + '_' + test_org['동']\n",
    "\n",
    "train_large = train_large.drop('구', axis=1)\n",
    "test_org = test_org.drop('구', axis=1)\n",
    "\n",
    "train_large = train_large.drop('동', axis=1)\n",
    "test_org = test_org.drop('동', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "omGiryQlXZiW"
   },
   "outputs": [],
   "source": [
    "k1 = train_large.groupby('new_구')['ECLO'].mean().reset_index()\n",
    "k2 = train_large.groupby('new_동')['ECLO'].mean().reset_index()\n",
    "\n",
    "고속도로1 = list(k1[k1['ECLO']>5]['new_구'])\n",
    "고속도로2 = list(k2[k2['ECLO']>5]['new_동'])\n",
    "\n",
    "train_large['고속도로여부1'] = train_large['new_구'].isin(고속도로1).astype(int)\n",
    "test_org['고속도로여부1'] = test_org['new_구'].isin(고속도로1).astype(int)\n",
    "\n",
    "train_large['고속도로여부2'] = train_large['new_동'].isin(고속도로2).astype(int)\n",
    "test_org['고속도로여부2'] = test_org['new_동'].isin(고속도로2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "id": "b6RzQr0NXZiW"
   },
   "outputs": [],
   "source": [
    "k1 = train_df.groupby('구')['ECLO'].mean().reset_index()\n",
    "k2 = train_df.groupby('동')['ECLO'].mean().reset_index()\n",
    "\n",
    "고속도로1 = list(k1[k1['ECLO']>5]['구'])\n",
    "고속도로2 = list(k2[k2['ECLO']>5]['동'])\n",
    "\n",
    "train_df['고속도로여부1'] = train_df['구'].isin(고속도로1).astype(int)\n",
    "test_df['고속도로여부1'] = test_df['구'].isin(고속도로1).astype(int)\n",
    "\n",
    "train_df['고속도로여부2'] = train_df['동'].isin(고속도로2).astype(int)\n",
    "test_df['고속도로여부2'] = test_df['동'].isin(고속도로2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "7aElxN3hXZiW"
   },
   "outputs": [],
   "source": [
    "a1 = train_df.groupby('동')['사망자수'].sum().reset_index()\n",
    "a2 = train_df.groupby('동')['중상자수'].sum().reset_index()\n",
    "a3 = train_df.groupby('동')['경상자수'].sum().reset_index()\n",
    "a4 = train_df.groupby('동')['부상자수'].sum().reset_index()\n",
    "\n",
    "a1.columns  = ['동','동사망자수']\n",
    "a2.columns  = ['동','동중상자수']\n",
    "a3.columns  = ['동','동경상자수']\n",
    "a4.columns  = ['동','동부상자수']\n",
    "\n",
    "train_df = pd.merge(train_df, a1, how='left', on=['동'])\n",
    "train_df = pd.merge(train_df, a2, how='left', on=['동'])\n",
    "train_df = pd.merge(train_df, a3, how='left', on=['동'])\n",
    "train_df = pd.merge(train_df, a4, how='left', on=['동'])\n",
    "\n",
    "test_df = pd.merge(test_df, a1, how='left', on=['동'])\n",
    "test_df = pd.merge(test_df, a2, how='left', on=['동'])\n",
    "test_df = pd.merge(test_df, a3, how='left', on=['동'])\n",
    "test_df = pd.merge(test_df, a4, how='left', on=['동'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "id": "xijz8PtJXZiX"
   },
   "outputs": [],
   "source": [
    "e1 = train_large.groupby('new_동')['사망자수'].sum().reset_index()\n",
    "e2 = train_large.groupby('new_동')['중상자수'].sum().reset_index()\n",
    "e3 = train_large.groupby('new_동')['경상자수'].sum().reset_index()\n",
    "e4 = train_large.groupby('new_동')['부상자수'].sum().reset_index()\n",
    "\n",
    "e1.columns  = ['new_동','동사망자수']\n",
    "e2.columns  = ['new_동','동중상자수']\n",
    "e3.columns  = ['new_동','동경상자수']\n",
    "e4.columns  = ['new_동','동부상자수']\n",
    "\n",
    "train_large = pd.merge(train_large, e1, how='left', on=['new_동'])\n",
    "train_large = pd.merge(train_large, e2, how='left', on=['new_동'])\n",
    "train_large = pd.merge(train_large, e3, how='left', on=['new_동'])\n",
    "train_large = pd.merge(train_large, e4, how='left', on=['new_동'])\n",
    "\n",
    "test_org = pd.merge(test_org, e1, how='left', on=['new_동'])\n",
    "test_org = pd.merge(test_org, e2, how='left', on=['new_동'])\n",
    "test_org = pd.merge(test_org, e3, how='left', on=['new_동'])\n",
    "test_org = pd.merge(test_org, e4, how='left', on=['new_동'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T12:28:00.421775Z",
     "iopub.status.busy": "2023-11-19T12:28:00.421425Z",
     "iopub.status.idle": "2023-11-19T12:28:00.459262Z",
     "shell.execute_reply": "2023-11-19T12:28:00.458314Z",
     "shell.execute_reply.started": "2023-11-19T12:28:00.421740Z"
    },
    "id": "h-hBGDJ5XZiX"
   },
   "outputs": [],
   "source": [
    "test_x_1 = test_df.drop(columns=['ID']).copy()\n",
    "train_x = train_df[test_x_1.columns].copy()\n",
    "train_y = train_df['ECLO'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T12:28:00.461473Z",
     "iopub.status.busy": "2023-11-19T12:28:00.460653Z",
     "iopub.status.idle": "2023-11-19T12:28:01.063937Z",
     "shell.execute_reply": "2023-11-19T12:28:01.062919Z",
     "shell.execute_reply.started": "2023-11-19T12:28:00.461435Z"
    },
    "id": "inMu7S_AXZiX"
   },
   "outputs": [],
   "source": [
    "#categorical 변수 인코딩\n",
    "str_col = ['요일', '기상상태', '노면상태', '사고유형', '도시', '구', '동', '도로형태1', '도로형태2', '사고유형_도로형태2']\n",
    "\n",
    "for i in str_col:\n",
    "    le = LabelEncoder()\n",
    "    le = le.fit(train_x[i])\n",
    "    train_x[i] = le.transform(train_x[i])\n",
    "\n",
    "    for label in np.unique(test_x_1[i]):\n",
    "        if label not in le.classes_:\n",
    "            le.classes_ = np.append(le.classes_, label)\n",
    "    test_x_1[i] = le.transform(test_x_1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "id": "Vit8PrNxXZiY"
   },
   "outputs": [],
   "source": [
    "#Time Cycling Transform\n",
    "##시간\n",
    "train_x['sin_hour'] = np.sin(2 * np.pi * train_x['시간']/23.0)\n",
    "train_x['cos_hour'] = np.cos(2 * np.pi * train_x['시간']/23.0)\n",
    "test_x_1['sin_hour'] = np.sin(2 * np.pi * test_x_1['시간']/23.0)\n",
    "test_x_1['cos_hour'] = np.cos(2 * np.pi * test_x_1['시간']/23.0)\n",
    "\n",
    "##날짜\n",
    "train_x['sin_date'] = -np.sin(2 * np.pi * (train_x['월']+train_x['일']/31)/12)\n",
    "train_x['cos_date'] = -np.sin(2 * np.pi * (train_x['월']+train_x['일']/31)/12)\n",
    "test_x_1['sin_date'] = -np.sin(2 * np.pi * (test_x_1['월']+test_x_1['일']/31)/12)\n",
    "test_x_1['cos_date'] = -np.sin(2 * np.pi * (test_x_1['월']+test_x_1['일']/31)/12)\n",
    "\n",
    "##월\n",
    "train_x['sin_month'] = -np.sin(2 * np.pi * train_x['월']/12.0)\n",
    "train_x['cos_month'] = -np.cos(2 * np.pi * train_x['월']/12.0)\n",
    "test_x_1['sin_month'] = -np.sin(2 * np.pi * test_x_1['월']/12.0)\n",
    "test_x_1['cos_month'] = -np.cos(2 * np.pi * test_x_1['월']/12.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "E0olaZhdXZiY"
   },
   "outputs": [],
   "source": [
    "#Time feature engineering\n",
    "train_x['covid-19'] = train_x['연'].apply(lambda x : 1 if x >= 2020  else 0)\n",
    "\n",
    "train_x['season'] = '-'\n",
    "train_x.loc[(train_x['월'] == 3) | (train_x['월'] == 4) | (train_x['월'] == 5), 'season'] = 0\n",
    "train_x.loc[(train_x['월'] == 6) | (train_x['월'] == 7) | (train_x['월'] == 8), 'season'] = 1\n",
    "train_x.loc[(train_x['월'] == 9) | (train_x['월'] == 10) | (train_x['월'] == 11), 'season'] = 2\n",
    "train_x.loc[(train_x['월'] == 12) | (train_x['월'] == 1) | (train_x['월'] == 2), 'season'] = 3\n",
    "train_x.loc[(train_x['season'] == '-'), 'season'] = 4\n",
    "\n",
    "train_x['group_time'] = '-'\n",
    "train_x.loc[(train_x['시간'] < 5), 'group_time'] = 0\n",
    "train_x.loc[(train_x['시간'] >= 5) & (train_x['시간'] < 11), 'group_time'] = 1\n",
    "train_x.loc[(train_x['시간'] >= 11) & (train_x['시간'] < 18), 'group_time'] = 2\n",
    "train_x.loc[(train_x['시간'] >= 18) & (train_x['시간'] <= 23), 'group_time'] = 3\n",
    "train_x.loc[(train_x['group_time'] == '-'), 'group_time'] = 4\n",
    "\n",
    "train_x['season'] = train_x['season'].astype(int)\n",
    "train_x['group_time'] = train_x['group_time'].astype(int)\n",
    "\n",
    "test_x_1['covid-19'] = test_x_1['연'].apply(lambda x : 1 if x >= 2020\n",
    "                                        else 0)\n",
    "\n",
    "test_x_1['season'] = '-'\n",
    "test_x_1.loc[(test_x_1['월'] == 3) | (test_x_1['월'] == 4) | (test_x_1['월'] == 5), 'season'] = 0\n",
    "test_x_1.loc[(test_x_1['월'] == 6) | (test_x_1['월'] == 7) | (test_x_1['월'] == 8), 'season'] = 1\n",
    "test_x_1.loc[(test_x_1['월'] == 9) | (test_x_1['월'] == 10) | (test_x_1['월'] == 11), 'season'] = 2\n",
    "test_x_1.loc[(test_x_1['월'] == 12) | (test_x_1['월'] == 1) | (test_x_1['월'] == 2), 'season'] = 3\n",
    "test_x_1.loc[(test_x_1['season'] == '-'), 'season'] = 4\n",
    "\n",
    "test_x_1['group_time'] = '-'\n",
    "test_x_1.loc[(test_x_1['시간'] < 5), 'group_time'] = 0\n",
    "test_x_1.loc[(test_x_1['시간'] >= 5) & (test_x_1['시간'] < 11), 'group_time'] = 1\n",
    "test_x_1.loc[(test_x_1['시간'] >= 11) & (test_x_1['시간'] < 18), 'group_time'] = 2\n",
    "test_x_1.loc[(test_x_1['시간'] >= 18) & (test_x_1['시간'] <= 23), 'group_time'] = 3\n",
    "test_x_1.loc[(test_x_1['group_time'] == '-'), 'group_time'] = 4\n",
    "\n",
    "test_x_1['season'] = test_x_1['season'].astype(int)\n",
    "test_x_1['group_time'] = test_x_1['group_time'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jq9D5bxRXZiY"
   },
   "source": [
    "## 3. Modeling : XGBOOST & CATBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gzl-pQc7XZiY"
   },
   "source": [
    "### 3-1. Only Train (DAEGU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frekoRsRtw42"
   },
   "source": [
    "### FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "id": "_wWloobxmMnr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "X = train_x\n",
    "y = train_y\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an XGBoost Regressor\n",
    "model = XGBRegressor(\n",
    "            max_depth=8,\n",
    "            learning_rate=0.01,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.9,\n",
    "            random_state=42,\n",
    "            min_child_weight=50,\n",
    "            objective='reg:squaredlogerror',\n",
    "            eval_metric='rmse')\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Display feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "sel_features = feature_importance_df[feature_importance_df['Importance']>0]['Feature']\n",
    "\n",
    "train_x = train_x[sel_features]\n",
    "test_x_1 = test_x_1[sel_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "id": "pNVP6RUknO82"
   },
   "outputs": [],
   "source": [
    "cat_features = ['요일','구' ,'주말', '새벽','사고유형', '도로형태1', '도로형태2','사고유형_도로형태2','group_time', '고속도로여부1', '고속도로여부2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "id": "HWNO8iidXZiY"
   },
   "outputs": [],
   "source": [
    "is_holdout = False\n",
    "iterations = 3000\n",
    "patience = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cDWSRdhcXZiZ"
   },
   "outputs": [],
   "source": [
    "models_xgb_1 = []\n",
    "models_lgb_1 = []\n",
    "models_cat_1 = []\n",
    "rmsle_scores = []\n",
    "n_split_list = [10,20]\n",
    "\n",
    "for i in [0,26,42,100,5000]:\n",
    "    for split in n_split_list:\n",
    "        fold_idx = 1\n",
    "        cv = StratifiedKFold(n_splits=split, shuffle=True, random_state=42)\n",
    "        for train_index, valid_index in cv.split(train_x,train_y):\n",
    "            X_train, X_valid = train_x.iloc[train_index], train_x.iloc[valid_index]\n",
    "            Y_train, Y_valid = train_y[train_index], train_y[valid_index]\n",
    "            log_Y_train, log_Y_valid = np.log1p(train_y[train_index]), np.log1p(train_y[valid_index])\n",
    "            print(\"=\"*50)\n",
    "\n",
    "            model_xgb = XGBRegressor(n_estimators = iterations, eta = 0.01, min_child_weight = 50,\n",
    "                        max_depth = 10, colsample_bytree = 0.9,\n",
    "                        subsample = 0.9, seed = i,\n",
    "                        objective = \"reg:squaredlogerror\",\n",
    "                        eval_metric = rmsle,\n",
    "                        tree_method=\"gpu_hist\")\n",
    "            model_xgb.fit(X_train, Y_train,\n",
    "                    eval_set=[(X_valid, Y_valid)],\n",
    "                    early_stopping_rounds=patience, verbose=100)\n",
    "\n",
    "\n",
    "            model_cat = CatBoostRegressor(iterations = iterations,\n",
    "                                random_state = i,\n",
    "                                task_type = \"GPU\",\n",
    "                                loss_function = \"RMSE\",\n",
    "                                eval_metric = \"RMSE\",\n",
    "                                cat_features = cat_features,\n",
    "                                one_hot_max_size = 6,\n",
    "                                random_strength = 5,\n",
    "                                #learning_rate=0.04\n",
    "                                      )\n",
    "            model_cat.fit(X_train, log_Y_train,\n",
    "                    eval_set=[(X_valid, log_Y_valid)],\n",
    "                    early_stopping_rounds=patience,\n",
    "                    verbose=100)\n",
    "\n",
    "            pred_xgb = model_xgb.predict(X_valid)\n",
    "            #pred_lgb = np.expm1(model_lgb.predict(X_valid))\n",
    "            pred_cat = np.expm1(model_cat.predict(X_valid))\n",
    "            pred = pred_cat*0.7 + pred_xgb*0.3   # + pred_lgb*0.4\n",
    "            score_xgb = np.sqrt(mean_squared_log_error(Y_valid,pred_xgb))\n",
    "            #score_lgb = np.sqrt(mean_squared_log_error(Y_valid,pred_lgb))\n",
    "            score_cat = np.sqrt(mean_squared_log_error(Y_valid,pred_cat))\n",
    "            score_ensemble = np.sqrt(mean_squared_log_error(Y_valid,pred))\n",
    "            print(fold_idx,\"/\",split,\"Fold Validation RMSLE score(XGB/LGBM/CAT/ENSEMBLE) :\", score_xgb,\"/\", score_cat,\"/\", score_ensemble)\n",
    "            models_xgb_1.append(model_xgb)\n",
    "            #models_lgb_1.append(model_lgb)\n",
    "            models_cat_1.append(model_cat)\n",
    "            rmsle_scores.append(score_ensemble)\n",
    "            fold_idx += 1\n",
    "            if is_holdout:\n",
    "                break\n",
    "    print(\"Validation : RMSLE scores for each fold:\", rmsle_scores)\n",
    "    print(\"Validation : RMSLE:\", np.mean(rmsle_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "id": "DGK7-7uycpXI"
   },
   "outputs": [],
   "source": [
    "preds_1 = []\n",
    "for i in range(150):\n",
    "    pred_xgb = models_xgb_1[i].predict(test_x_1)\n",
    "    pred_cat = np.expm1(models_cat_1[i].predict(test_x_1))\n",
    "    pred = pred_cat*0.5 + pred_xgb*0.5\n",
    "    preds_1.append(pred)\n",
    "\n",
    "preds_1 = np.mean(preds_1 , axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4p1PfmiPXZiZ"
   },
   "source": [
    "### 3-2. Train + countrywide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "id": "OXcLE9reXZiZ"
   },
   "outputs": [],
   "source": [
    "test_x_2 = test_org.drop(columns=['ID']).copy()\n",
    "train_x = train_large[test_x_2.columns].copy()\n",
    "train_y = train_large['ECLO'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RnE5tSYWXZiZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#categorical 변수 인코딩\n",
    "str_col = ['요일','기상상태', '노면상태', '사고유형', '도시', 'new_구', 'new_동', '도로형태1', '도로형태2', '사고유형_도로형태2']\n",
    "\n",
    "for i in str_col:\n",
    "    le = LabelEncoder()\n",
    "    le = le.fit(train_x[i])\n",
    "    train_x[i] = le.transform(train_x[i])\n",
    "\n",
    "    for label in np.unique(test_x_2[i]):\n",
    "        if label not in le.classes_:\n",
    "            le.classes_ = np.append(le.classes_, label)\n",
    "    test_x_2[i] = le.transform(test_x_2[i])\n",
    "\n",
    "display(train_x.head())\n",
    "display(test_x_2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "fb8JzqcoXZia"
   },
   "outputs": [],
   "source": [
    "#Time Cycling Transform\n",
    "##시간\n",
    "train_x['sin_hour'] = np.sin(2 * np.pi * train_x['시간']/23.0)\n",
    "train_x['cos_hour'] = np.cos(2 * np.pi * train_x['시간']/23.0)\n",
    "test_x_2['sin_hour'] = np.sin(2 * np.pi * test_x_2['시간']/23.0)\n",
    "test_x_2['cos_hour'] = np.cos(2 * np.pi * test_x_2['시간']/23.0)\n",
    "\n",
    "##날짜\n",
    "train_x['sin_date'] = -np.sin(2 * np.pi * (train_x['월']+train_x['일']/31)/12)\n",
    "train_x['cos_date'] = -np.sin(2 * np.pi * (train_x['월']+train_x['일']/31)/12)\n",
    "test_x_2['sin_date'] = -np.sin(2 * np.pi * (test_x_2['월']+test_x_2['일']/31)/12)\n",
    "test_x_2['cos_date'] = -np.sin(2 * np.pi * (test_x_2['월']+test_x_2['일']/31)/12)\n",
    "\n",
    "##월\n",
    "train_x['sin_month'] = -np.sin(2 * np.pi * train_x['월']/12.0)\n",
    "train_x['cos_month'] = -np.cos(2 * np.pi * train_x['월']/12.0)\n",
    "test_x_2['sin_month'] = -np.sin(2 * np.pi * test_x_2['월']/12.0)\n",
    "test_x_2['cos_month'] = -np.cos(2 * np.pi * test_x_2['월']/12.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "id": "xyghmnFUXZia"
   },
   "outputs": [],
   "source": [
    "#Time feature engineering\n",
    "train_x['covid-19'] = train_x['연'].apply(lambda x : 1 if x >= 2020\n",
    "                                        else 0)\n",
    "# train_x['holiday'] = train_x['요일'].apply(lambda x : 2 if x == 6\n",
    "#                                         else 1 if x == 5\n",
    "#                                         else 0)\n",
    "train_x['season'] = '-'\n",
    "train_x.loc[(train_x['월'] == 3) | (train_x['월'] == 4) | (train_x['월'] == 5), 'season'] = 0\n",
    "train_x.loc[(train_x['월'] == 6) | (train_x['월'] == 7) | (train_x['월'] == 8), 'season'] = 1\n",
    "train_x.loc[(train_x['월'] == 9) | (train_x['월'] == 10) | (train_x['월'] == 11), 'season'] = 2\n",
    "train_x.loc[(train_x['월'] == 12) | (train_x['월'] == 1) | (train_x['월'] == 2), 'season'] = 3\n",
    "train_x.loc[(train_x['season'] == '-'), 'season'] = 4\n",
    "\n",
    "train_x['group_time'] = '-'\n",
    "train_x.loc[(train_x['시간'] < 5), 'group_time'] = 0\n",
    "train_x.loc[(train_x['시간'] >= 5) & (train_x['시간'] < 11), 'group_time'] = 1\n",
    "train_x.loc[(train_x['시간'] >= 11) & (train_x['시간'] < 18), 'group_time'] = 2\n",
    "train_x.loc[(train_x['시간'] >= 18) & (train_x['시간'] <= 23), 'group_time'] = 3\n",
    "train_x.loc[(train_x['group_time'] == '-'), 'group_time'] = 4\n",
    "\n",
    "train_x['season'] = train_x['season'].astype(int)\n",
    "train_x['group_time'] = train_x['group_time'].astype(int)\n",
    "\n",
    "test_x_2['covid-19'] = test_x_2['연'].apply(lambda x : 1 if x >= 2020\n",
    "                                        else 0)\n",
    "# test_x_2['holiday'] = test_x_2['요일'].apply(lambda x : 2 if x == 6\n",
    "#                                         else 1 if x == 5\n",
    "#                                         else 0)\n",
    "test_x_2['season'] = '-'\n",
    "test_x_2.loc[(test_x_2['월'] == 3) | (test_x_2['월'] == 4) | (test_x_2['월'] == 5), 'season'] = 0\n",
    "test_x_2.loc[(test_x_2['월'] == 6) | (test_x_2['월'] == 7) | (test_x_2['월'] == 8), 'season'] = 1\n",
    "test_x_2.loc[(test_x_2['월'] == 9) | (test_x_2['월'] == 10) | (test_x_2['월'] == 11), 'season'] = 2\n",
    "test_x_2.loc[(test_x_2['월'] == 12) | (test_x_2['월'] == 1) | (test_x_2['월'] == 2), 'season'] = 3\n",
    "test_x_2.loc[(test_x_2['season'] == '-'), 'season'] = 4\n",
    "\n",
    "test_x_2['group_time'] = '-'\n",
    "test_x_2.loc[(test_x_2['시간'] < 5), 'group_time'] = 0\n",
    "test_x_2.loc[(test_x_2['시간'] >= 5) & (test_x_2['시간'] < 11), 'group_time'] = 1\n",
    "test_x_2.loc[(test_x_2['시간'] >= 11) & (test_x_2['시간'] < 18), 'group_time'] = 2\n",
    "test_x_2.loc[(test_x_2['시간'] >= 18) & (test_x_2['시간'] <= 23), 'group_time'] = 3\n",
    "test_x_2.loc[(test_x_2['group_time'] == '-'), 'group_time'] = 4\n",
    "\n",
    "test_x_2['season'] = test_x_2['season'].astype(int)\n",
    "test_x_2['group_time'] = test_x_2['group_time'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COveRq4ft-kt"
   },
   "source": [
    "### FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "id": "T9jFwaW1qsuI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "X = train_x\n",
    "y = train_y\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an XGBoost Regressor\n",
    "model = XGBRegressor(\n",
    "            max_depth=8,\n",
    "            learning_rate=0.01,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.9,\n",
    "            random_state=42,\n",
    "            min_child_weight=50,\n",
    "            objective='reg:squaredlogerror',\n",
    "            eval_metric='rmse')\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Display feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "sel_features = feature_importance_df[feature_importance_df['Importance']>0]['Feature']\n",
    "\n",
    "train_x = train_x[sel_features]\n",
    "test_x_2 = test_x_2[sel_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YIQwRv_gyaxZ"
   },
   "outputs": [],
   "source": [
    "train_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "id": "y46sfCQ2rQUu"
   },
   "outputs": [],
   "source": [
    "cat_features = ['고속도로여부2', '사고유형', '사고유형_도로형태2', '주말', 'weekday', '고속도로여부1','도로형태2', 'new_구','new_동', 'group_time','도시','도로형태1','기상상태','노면상태']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXroVOt3tCgO"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "id": "aMOWprbaXZia"
   },
   "outputs": [],
   "source": [
    "is_holdout = False\n",
    "iterations = 30000\n",
    "patience = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDz_Go-rXZia"
   },
   "outputs": [],
   "source": [
    "models_xgb_2 = []\n",
    "models_lgb_2 = []\n",
    "models_cat_2 = []\n",
    "rmsle_scores = []\n",
    "n_split_list = [10,20]\n",
    "for i in [0,26,42,100,5000]:\n",
    "    for split in n_split_list:\n",
    "        fold_idx = 1\n",
    "        cv = StratifiedKFold(n_splits=split, shuffle=True, random_state=42)\n",
    "        for train_index, valid_index in cv.split(train_x,train_y):\n",
    "            X_train, X_valid = train_x.iloc[train_index], train_x.iloc[valid_index]\n",
    "            Y_train, Y_valid = train_y[train_index], train_y[valid_index]\n",
    "            log_Y_train, log_Y_valid = np.log1p(train_y[train_index]), np.log1p(train_y[valid_index])\n",
    "            print(\"=\"*50)\n",
    "\n",
    "            model_xgb = XGBRegressor(n_estimators = iterations, eta = 0.01, min_child_weight = 50,\n",
    "                        max_depth = 10, colsample_bytree = 0.9,\n",
    "                        subsample = 0.9, seed = i,\n",
    "                        objective = 'reg:squaredlogerror',\n",
    "                        eval_metric = rmsle,\n",
    "                        tree_method=\"gpu_hist\")\n",
    "\n",
    "            model_xgb.fit(X_train, Y_train,\n",
    "                    eval_set=[(X_valid, Y_valid)],\n",
    "                    early_stopping_rounds=patience, verbose=100)\n",
    "\n",
    "            model_cat = CatBoostRegressor(iterations = iterations,\n",
    "                                random_state = i,\n",
    "                                task_type = \"GPU\",\n",
    "                                loss_function = \"RMSE\",\n",
    "                                eval_metric = \"RMSE\",\n",
    "                                cat_features=cat_features,\n",
    "                                one_hot_max_size=6,\n",
    "                                random_strength = 10,\n",
    "                                #learning_rate=0.01\n",
    "                                      )\n",
    "\n",
    "            model_cat.fit(X_train, log_Y_train,\n",
    "                    eval_set=[(X_valid, log_Y_valid)],\n",
    "                    early_stopping_rounds=patience,\n",
    "                    verbose=100)\n",
    "\n",
    "            pred_xgb = model_xgb.predict(X_valid)\n",
    "            pred_cat = np.expm1(model_cat.predict(X_valid))\n",
    "            pred = pred_cat*0.5 + pred_xgb*0.5    # + pred_lgb*0.4\n",
    "            score_xgb = np.sqrt(mean_squared_log_error(Y_valid,pred_xgb))\n",
    "            score_cat = np.sqrt(mean_squared_log_error(Y_valid,pred_cat))\n",
    "            score_ensemble = np.sqrt(mean_squared_log_error(Y_valid,pred))\n",
    "            print(fold_idx,\"/\",split,\"Fold Validation RMSLE score(XGB/LGBM/CAT/ENSEMBLE) :\", score_xgb,\"/\", score_cat,\"/\", score_ensemble)\n",
    "            models_xgb_2.append(model_xgb)\n",
    "            models_cat_2.append(model_cat)\n",
    "            rmsle_scores.append(score_ensemble)\n",
    "            fold_idx += 1\n",
    "            if is_holdout:\n",
    "                break\n",
    "print(\"Validation : RMSLE scores for each fold:\", rmsle_scores)\n",
    "print(\"Validation : RMSLE:\", np.mean(rmsle_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Vj_IsfGXZia"
   },
   "source": [
    "## 4. Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "id": "TxiTMfUjXZib"
   },
   "outputs": [],
   "source": [
    "preds_1 = []\n",
    "for i in range(150):\n",
    "    pred_xgb = models_xgb_1[i].predict(test_x_1)\n",
    "    pred_cat = np.expm1(models_cat_1[i].predict(test_x_1))\n",
    "    pred = pred_cat*0.5 + pred_xgb*0.5\n",
    "    preds_1.append(pred)\n",
    "\n",
    "preds_1 = np.mean(preds_1 , axis = 0)\n",
    "\n",
    "preds_2 = []\n",
    "for i in range(150):\n",
    "    pred_xgb = models_xgb_2[i].predict(test_x_2)\n",
    "    pred_cat = np.expm1(models_cat_2[i].predict(test_x_2))\n",
    "    pred = pred_cat*0.5 + pred_xgb*0.5\n",
    "    preds_2.append(pred)\n",
    "\n",
    "preds_2 = np.mean(preds_2 , axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T12:28:04.484469Z",
     "iopub.status.busy": "2023-11-19T12:28:04.483638Z",
     "iopub.status.idle": "2023-11-19T12:28:05.220467Z",
     "shell.execute_reply": "2023-11-19T12:28:05.219587Z",
     "shell.execute_reply.started": "2023-11-19T12:28:04.484434Z"
    },
    "id": "lbqAMqBnXZib"
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"/content/drive/MyDrive/대구_교통사고_피해_예측_AI경진대회/open/sample_submission.csv\")\n",
    "\n",
    "sample_submission[\"ECLO_1\"] = preds_1\n",
    "sample_submission[\"ECLO_2\"] = preds_2\n",
    "sample_submission[\"ECLO\"] = sample_submission[\"ECLO_1\"] * 0.7 + sample_submission[\"ECLO_2\"] * 0.3\n",
    "\n",
    "sample_submission = sample_submission[['ID','ECLO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "UFYjGVQcXZib"
   },
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"/content/drive/MyDrive/대구_교통사고_피해_예측_AI경진대회/open/COLAB_FINAL.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4025443,
     "sourceId": 7002395,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
