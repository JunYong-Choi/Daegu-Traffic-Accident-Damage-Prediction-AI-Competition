{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "pbl_cell_type": "markdown",
    "step_id": 4887,
    "step_number": 0
   },
   "source": [
    "# **대구 교통 사고 피해 예측 AI 경진대회 Baseline Code**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment\n",
    "- GPU 0  : NVIDIA GeForce RTX 3080 Ti Laptop GPU\n",
    "- GPU 1  : AMD Radeon(TM) Graphics\n",
    "- CPU : AMD Ryzen 9 6900HX with Radeon Graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "pbl_cell_type": "hidden_setup_code",
    "step_id": 4887,
    "step_number": 0
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "fe = fm.FontEntry(fname = 'MaruBuri-Regular.otf', name = 'MaruBuri')\n",
    "fm.fontManager.ttflist.insert(0, fe)\n",
    "plt.rc('font', family='MaruBuri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Python & library version --------------------------\n",
      "Python version: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas version: 2.0.3\n",
      "numpy version: 1.21.5\n",
      "matplotlib version: 3.5.2\n",
      "tqdm version: 4.64.1\n",
      "xgboost version: 1.7.2\n",
      "lightgbm version: 3.3.3\n",
      "catboost version: 1.1.1\n",
      "seaborn version: 0.11.2\n",
      "scikit-learn version: 1.0.2\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tqdm as tq\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cat\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "print(\"-------------------------- Python & library version --------------------------\")\n",
    "print(\"Python version: {}\".format(sys.version))\n",
    "print(\"pandas version: {}\".format(pd.__version__))\n",
    "print(\"numpy version: {}\".format(np.__version__))\n",
    "print(\"matplotlib version: {}\".format(matplotlib.__version__))\n",
    "print(\"tqdm version: {}\".format(tq.__version__))\n",
    "print(\"xgboost version: {}\".format(xgb.__version__))\n",
    "print(\"lightgbm version: {}\".format(lgb.__version__))\n",
    "print(\"catboost version: {}\".format(cat.__version__))\n",
    "print(\"seaborn version: {}\".format(sns.__version__))\n",
    "print(\"scikit-learn version: {}\".format(skl.__version__))\n",
    "print(\"------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pbl_cell_type": "markdown",
    "step_id": 5096,
    "step_number": 1
   },
   "source": [
    "## **Fixed Random Seed**  \n",
    "\n",
    "seed 값에 의해 동일한 코드를 사용해도 결과가 다를 수 있기에, 동일한 결과를 위해 seed 값을 고정시킵니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pbl_cell_type": "code",
    "step_id": 5096,
    "step_number": 1
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pbl_cell_type": "markdown",
    "step_id": 5096,
    "step_number": 1
   },
   "source": [
    "## **데이터 불러오기 및 상위행 확인**  \n",
    "\n",
    "train.csv, test.csv 파일을 로드하여 상위행을 출력해 봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pbl_cell_type": "code",
    "step_id": 5096,
    "step_number": 1
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "train_org = pd.read_csv('train.csv') \n",
    "test_org = pd.read_csv('test.csv')\n",
    "countrywide_accident = pd.read_csv('./data/countrywide_accident.csv', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_org = pd.concat([countrywide_accident,train_org],axis=0)\n",
    "train_org = train_org.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pbl_cell_type": "code",
    "step_id": 5096,
    "step_number": 1
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pbl_cell_type": "markdown",
    "step_id": 5168,
    "step_number": 2
   },
   "source": [
    "## **데이터 전처리**  \n",
    "\n",
    "현재 '사고일시', '시군구', '도로형태' 컬럼은 반복되는 패턴으로 여러 정보를 포함하고 있습니다\n",
    "이런 반복되는 패턴을 일반화하면 pandas에서 제공하는 str.extract를 통해 한 번에 추출 가능합니다  \n",
    "\n",
    "## **파생 변수 생성 1 : 날짜, 시간정보 생성**\n",
    "\n",
    "'사고일시' 컬럼으로 부터 연도, 월, 일, 시간 정보 추출 및 변환 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_org['사고일시'] = pd.to_datetime(train_org['사고일시'])\n",
    "test_org['사고일시'] = pd.to_datetime(test_org['사고일시'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_org.copy()\n",
    "test_df = test_org.copy()\n",
    "\n",
    "for df in [train_df, test_df]:\n",
    "    df['연'] = df['사고일시'].dt.year\n",
    "    df['월'] = df['사고일시'].dt.month\n",
    "    df['일'] = df['사고일시'].dt.day\n",
    "    df['monthday'] = df.apply(lambda row: str(row['월']) + '-' + str(row['일']), axis=1)\n",
    "    df['시간'] = df['사고일시'].dt.hour\n",
    "    df['weekday'] = df['사고일시'].dt.weekday\n",
    "    df['weekofyear'] = (df['사고일시'].dt.isocalendar().week).astype(int)\n",
    "    df['새벽'] = df['시간'].isin([0,1,2,3,4,5,6]).astype(int)\n",
    "    df['밤'] = df['시간'].isin([21,22,23]).astype(int)\n",
    "    df['주말'] = df['weekday'].isin([5,6]).astype(int)\n",
    "    df['주중'] = df['weekday'].isin([0,1,2,3,4]).astype(int)\n",
    "    df['국가공휴일'] = df['monthday'].isin(['1-1','3-1','5-5','6-6','8-15','10-3','10-9','12-25','12-31']).astype(int)\n",
    "    df['covid-19'] = df['연'].apply(lambda x : 1 if x >= 2020\n",
    "                                        else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time Cycling Transform \n",
    "##시간\n",
    "train_df['sin_hour'] = np.sin(2 * np.pi * train_df['시간']/23.0)\n",
    "train_df['cos_hour'] = np.cos(2 * np.pi * train_df['시간']/23.0)\n",
    "test_df['sin_hour'] = np.sin(2 * np.pi * test_df['시간']/23.0)\n",
    "test_df['cos_hour'] = np.cos(2 * np.pi * test_df['시간']/23.0)\n",
    "\n",
    "##날짜\n",
    "train_df['sin_date'] = -np.sin(2 * np.pi * (train_df['월']+train_df['일']/31)/12)\n",
    "train_df['cos_date'] = -np.sin(2 * np.pi * (train_df['월']+train_df['일']/31)/12)\n",
    "test_df['sin_date'] = -np.sin(2 * np.pi * (test_df['월']+test_df['일']/31)/12)\n",
    "test_df['cos_date'] = -np.sin(2 * np.pi * (test_df['월']+test_df['일']/31)/12)\n",
    "\n",
    "##월\n",
    "train_df['sin_month'] = -np.sin(2 * np.pi * train_df['월']/12.0)\n",
    "train_df['cos_month'] = -np.cos(2 * np.pi * train_df['월']/12.0)\n",
    "test_df['sin_month'] = -np.sin(2 * np.pi * test_df['월']/12.0)\n",
    "test_df['cos_month'] = -np.cos(2 * np.pi * test_df['월']/12.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=['사고일시','monthday']) # 정보 추출이 완료된 '사고일시' 컬럼은 제거합니다 \n",
    "test_df = test_df.drop(columns=['사고일시','monthday'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pbl_cell_type": "markdown",
    "step_id": 5169,
    "step_number": 3
   },
   "source": [
    "## **파생 변수 생성 2 : 공간(위치) 정보 생성** \n",
    "\n",
    "'시군구' 컬럼으로부터 의미 있는 공산 정보를 추출 및 변환 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pbl_cell_type": "code",
    "step_id": 5169,
    "step_number": 3
   },
   "outputs": [],
   "source": [
    "location_pattern = r'(\\S+) (\\S+) (\\S+)'\n",
    "\n",
    "train_df[['도시', '구', '동']] = train_org['시군구'].str.extract(location_pattern)\n",
    "train_df = train_df.drop(columns=['시군구'])\n",
    "\n",
    "test_df[['도시', '구', '동']] = test_org['시군구'].str.extract(location_pattern)\n",
    "test_df = test_df.drop(columns=['시군구'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[(train_df['도시']=='울산광역시') & (train_df['구']=='중구'),'구']='울산중구'\n",
    "train_df.loc[(train_df['도시']=='울산광역시') & (train_df['구']=='남구'),'구']='울산남구'\n",
    "train_df.loc[(train_df['도시']=='울산광역시') & (train_df['구']=='동구'),'구']='울산동구'\n",
    "train_df.loc[(train_df['도시']=='울산광역시') & (train_df['구']=='북구'),'구']='울산북구'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[(train_df['도시']=='대전광역시') & (train_df['구']=='동구'),'구']='대전동구'\n",
    "train_df.loc[(train_df['도시']=='대전광역시') & (train_df['구']=='중구'),'구']='대전중구'\n",
    "train_df.loc[(train_df['도시']=='대전광역시') & (train_df['구']=='서구'),'구']='대전서구'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[(train_df['도시']=='인천광역시') & (train_df['구']=='중구'),'구']='인천중구'\n",
    "train_df.loc[(train_df['도시']=='인천광역시') & (train_df['구']=='동구'),'구']='인천동구'\n",
    "train_df.loc[(train_df['도시']=='인천광역시') & (train_df['구']=='서구'),'구']='인천서구'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[(train_df['도시']=='대구광역시') & (train_df['구']=='중구'),'구']='대구중구'\n",
    "train_df.loc[(train_df['도시']=='대구광역시') & (train_df['구']=='동구'),'구']='대구동구'\n",
    "train_df.loc[(train_df['도시']=='대구광역시') & (train_df['구']=='서구'),'구']='대구서구'\n",
    "train_df.loc[(train_df['도시']=='대구광역시') & (train_df['구']=='남구'),'구']='대구남구'\n",
    "train_df.loc[(train_df['도시']=='대구광역시') & (train_df['구']=='북구'),'구']='대구북구'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[(train_df['도시']=='부산광역시') & (train_df['구']=='중구'),'구']='부산중구'\n",
    "train_df.loc[(train_df['도시']=='부산광역시') & (train_df['구']=='동구'),'구']='부산동구'\n",
    "train_df.loc[(train_df['도시']=='부산광역시') & (train_df['구']=='서구'),'구']='부산서구'\n",
    "train_df.loc[(train_df['도시']=='부산광역시') & (train_df['구']=='남구'),'구']='부산남구'\n",
    "train_df.loc[(train_df['도시']=='부산광역시') & (train_df['구']=='북구'),'구']='부산북구'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[(train_df['도시']=='광주광역시') & (train_df['구']=='동구'),'구']='광주동구'\n",
    "train_df.loc[(train_df['도시']=='광주광역시') & (train_df['구']=='서구'),'구']='광주서구'\n",
    "train_df.loc[(train_df['도시']=='광주광역시') & (train_df['구']=='북구'),'구']='광주북구'\n",
    "train_df.loc[(train_df['도시']=='광주광역시') & (train_df['구']=='남구'),'구']='광주남구'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[(test_df['도시']=='대구광역시') & (test_df['구']=='중구'),'구']='대구중구'\n",
    "test_df.loc[(test_df['도시']=='대구광역시') & (test_df['구']=='동구'),'구']='대구동구'\n",
    "test_df.loc[(test_df['도시']=='대구광역시') & (test_df['구']=='서구'),'구']='대구서구'\n",
    "test_df.loc[(test_df['도시']=='대구광역시') & (test_df['구']=='남구'),'구']='대구남구'\n",
    "test_df.loc[(test_df['도시']=='대구광역시') & (test_df['구']=='북구'),'구']='대구북구'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[(train_df['도시']=='서울특별시') & (train_df['구']=='강서구'),'구']='서울강서구'\n",
    "train_df.loc[(train_df['도시']=='부산광역시') & (train_df['구']=='강서구'),'구']='부산강서구'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[(train_df['도시']=='경상남도') & (train_df['구']=='고성군'),'구']='경상고성'\n",
    "train_df.loc[(train_df['도시']=='강원도') & (train_df['구']=='고성군'),'구']='강원고성'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[~train_df['도시'].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = train_df.groupby('구')['ECLO'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2 = train_df.groupby('동')['ECLO'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "고속도로1 = list(k1[k1['ECLO']>5]['구'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "고속도로2 = list(k2[k2['ECLO']>5]['동'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['고속도로여부1'] = train_df['구'].isin(고속도로1).astype(int)\n",
    "test_df['고속도로여부1'] = test_df['구'].isin(고속도로1).astype(int)\n",
    "\n",
    "train_df['고속도로여부2'] = train_df['동'].isin(고속도로2).astype(int)\n",
    "test_df['고속도로여부2'] = test_df['동'].isin(고속도로2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = train_df.groupby('동')['사망자수'].sum().reset_index()\n",
    "a2 = train_df.groupby('동')['중상자수'].sum().reset_index()\n",
    "a3 = train_df.groupby('동')['경상자수'].sum().reset_index()\n",
    "a4 = train_df.groupby('동')['부상자수'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1.columns  = ['동','동사망자수']\n",
    "a2.columns  = ['동','동중상자수']\n",
    "a3.columns  = ['동','동경상자수']\n",
    "a4.columns  = ['동','동부상자수']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.merge(train_df, a1, how='left', on=['동'])\n",
    "train_df = pd.merge(train_df, a2, how='left', on=['동'])\n",
    "train_df = pd.merge(train_df, a3, how='left', on=['동'])\n",
    "train_df = pd.merge(train_df, a4, how='left', on=['동'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.merge(test_df, a1, how='left', on=['동'])\n",
    "test_df = pd.merge(test_df, a2, how='left', on=['동'])\n",
    "test_df = pd.merge(test_df, a3, how='left', on=['동'])\n",
    "test_df = pd.merge(test_df, a4, how='left', on=['동'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pbl_cell_type": "code",
    "step_id": 5170,
    "step_number": 4
   },
   "outputs": [],
   "source": [
    "road_pattern = r'(.+) - (.+)'\n",
    "\n",
    "train_df[['도로형태1', '도로형태2']] = train_df['도로형태'].str.extract(road_pattern)\n",
    "train_df = train_df.drop(columns=['도로형태'])\n",
    "\n",
    "test_df[['도로형태1', '도로형태2']] = test_df['도로형태'].str.extract(road_pattern)\n",
    "test_df = test_df.drop(columns=['도로형태'])\n",
    "\n",
    "display(f\"columns of train_df : {train_df.columns}\")\n",
    "display(f\"columns of test_df : {test_df.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['도로형태2'] != '철길건널목'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['기상상태'] != '안개'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_1 = train_df.reset_index(drop=True)\n",
    "test_df_1 = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_1 = test_df_1.drop(columns=['ID']).copy()\n",
    "train_x_1 = train_df_1[test_x_1.columns].copy()\n",
    "\n",
    "train_y_1 = train_df_1['사망자수'].copy()\n",
    "train_y_2 = train_df_1['중상자수'].copy()\n",
    "train_y_3 = train_df_1['경상자수'].copy()\n",
    "train_y_4 = train_df_1['부상자수'].copy()\n",
    "train_y_5 = train_df_1['ECLO'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "categorical_features = list(train_x_1.dtypes[train_x_1.dtypes == \"object\"].index)\n",
    "# 추출된 문자열 변수 확인\n",
    "\n",
    "for i in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    le=le.fit(train_x_1[i]) \n",
    "    train_x_1[i]=le.transform(train_x_1[i])\n",
    "    \n",
    "    for case in np.unique(test_x_1[i]):\n",
    "        if case not in le.classes_: \n",
    "            le.classes_ = np.append(le.classes_, case) \n",
    "    test_x_1[i]=le.transform(test_x_1[i])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "X = train_x_1\n",
    "y = train_y_5\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,np.log1p(y), test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an XGBoost Regressor\n",
    "model = XGBRegressor(\n",
    "            max_depth=8,\n",
    "            learning_rate=0.01,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.9,\n",
    "            random_state=42,\n",
    "            min_child_weight=50,\n",
    "            objective='reg:squarederror',\n",
    "            eval_metric='rmse')\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Display feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_features = feature_importance_df[feature_importance_df['Importance']>0]['Feature']\n",
    "\n",
    "train_x_1 = train_x_1[sel_features]\n",
    "test_x_1 = test_x_1[sel_features]\n",
    "\n",
    "train_x_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 3000\n",
    "patience = 100\n",
    "is_holdout = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# 경고 끄기\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "models_1 = []\n",
    "rmse_scores = []\n",
    "n_split_list = [10,20]\n",
    "for i in [0,11,25,1523,557,156,42,69,1125,5000]:\n",
    "    for split in n_split_list:\n",
    "        fold_idx = 1\n",
    "        cv = StratifiedKFold(n_splits=split, shuffle=True, random_state=i)\n",
    "        for train_index, valid_index in cv.split(train_x_1,train_y_5):\n",
    "            X_train, X_valid = train_x_1.iloc[train_index], train_x_1.iloc[valid_index]\n",
    "            Y_train, Y_valid = train_y_5[train_index], train_y_5[valid_index]\n",
    "            log_Y_train, log_Y_valid = np.log1p(train_y_5[train_index]), np.log1p(train_y_5[valid_index])\n",
    "            print(\"=\"*50)\n",
    "\n",
    "            model = xgb.XGBRegressor(\n",
    "                booster='gbtree',\n",
    "                tree_method = 'gpu_hist',\n",
    "                #device = 'gpu',\n",
    "                n_estimators=iterations,\n",
    "                max_depth=8,\n",
    "                learning_rate=0.01,\n",
    "                subsample=0.9,\n",
    "                colsample_bytree=0.9,\n",
    "                random_state=i,\n",
    "                min_child_weight=50,\n",
    "                objective='reg:squarederror',  # XGBoost에서 Tweedie 손실 함수\n",
    "                eval_metric = 'rmse'\n",
    "            )\n",
    "\n",
    "            model.fit(\n",
    "                X_train, log_Y_train,\n",
    "                eval_set=[(X_valid, log_Y_valid)],\n",
    "                early_stopping_rounds=patience,\n",
    "                verbose=100\n",
    "            )\n",
    "\n",
    "            pred = model.predict(X_valid)\n",
    "\n",
    "            models_1.append(model)\n",
    "            fold_idx += 1\n",
    "            if is_holdout:\n",
    "                break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_1  = []\n",
    "for i in (range(300)):\n",
    "    pred = models_1[i].predict(test_x_1)\n",
    "    preds_1.append(np.expm1(pred))\n",
    "\n",
    "preds_1 = np.mean(preds_1 , axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_submission = sample_submission.copy()\n",
    "baseline_submission['ECLO'] = preds_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_submission.to_csv('1209_ENS_SECOND.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENSEMBLE WITH COLAB_FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "answer1 = pd.read_csv('1209_ENS_SECOND.csv')\n",
    "answer2 = pd.read_csv('COLAB_FINAL.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = answer1['ECLO']* 0.2 + answer2['ECLO']*0.8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "final_submission = sample_submission.copy()\n",
    "final_submission['ECLO'] = k1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission.to_csv(\"private_검증용.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
